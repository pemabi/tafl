{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tablut via Reinforcement Learning\n",
    "---\n",
    "The goal here is to construct an engine to play the historical Scandinavian game Tablut, using a tabula rasa Reinforcement Learning approach as developed by Alpha Zero and distributed by Leela Chess. In this notebook I'll run through all of my code, starting with logic to play the game, then designing a model to provide move probabilities and positional assesment, then setting up a MCTS pipeline to the generate data to iteratively train the model.\n",
    "\n",
    "__About Tablut:__\\\n",
    "Tablut as drawn by Linnaeus\\\n",
    "![Tablut Setup](/Users/peterbitman/Desktop/tafl/data/linnaeus-1.png)\n",
    "\n",
    "__Challenges:__\n",
    "- Extreme lack of compute\n",
    "- Particularly important during self-play\n",
    "- Vaguery in rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Thoughts\n",
    "\n",
    "__On Gameplay:__\n",
    "\n",
    "The first challenge is to create an engine that can play the game under the exact rules. This engine should be reasonably efficient, as the gameplay element is the most expensive in the pipeline. It should also be relatively straighforward so that I can call the important methods (finding moves, applying moves, checking for terminal state) in a practical way during MCTS. In fact, it should __only deal with the basic mechanics__. Every other element (logging, tracking, tensor assembly, etc) should be handled by the class methods that will run the game during our training pipeline. This way, we will be able to reuse our logic for playing the game and expanding our search tree.\n",
    "\n",
    "This challenge is fairly straightforward, and I have already done this for my first 1D implementation. However, because I am using a more complex model, and am attempting to leverage CNNs, and am trying to do this with a sophisticated enough approach to justify sinking some compute units into game simulation and training, I want to use a more structured approach to considering input format. This brings us to the second challenge - identifying a reasonable representation of Tablut for our model and then implementing the translation of our gamestate into this image. \n",
    "\n",
    "__On Input:__\n",
    "\n",
    "The first element is straightforward and just comprises the information that we need to describe the position currently on the board. 4x 9x9 bitvectors does this for us, the first is set to 1 for WHITE else 0; the second encodes 1 for BLACK else 0; the third encodes 1 for the KING else 0; the fourth is less obvious, encoding the Castle square if it is empty with 1 else 0. However, this only gives us the game representation we were have if we had just walked up behind two players and glanced over the board - and unfortunately the state of this game (in a Markovian sense of 'state') is not accurately reflected only by piece positions. There are rules surrounding continuous repetitions. Unfortunately, these rules are murky and, worse, recently contested. \n",
    "\n",
    "__Unfortunate Foray into Repetition Rules in Tafl Games:__\n",
    "\n",
    "The [Aage Nielsen](http://aagenielsen.dk/historical_hnefatafl_rules.php) rules state that repetitions are not allowed and result in a loss for White. \n",
    "\n",
    "In a [leaflet](http://tafl.cyningstan.com/data-download/1012/copenhagen-hnefatafl-leaflet) written by Damian Walker, the rule for _Copenhagen Hneftatl_ states:\n",
    "<blockquote>\n",
    "\"Perpetual repetition is illegal. If the board position is repeated three times, the player in control of the situation must find another move.\"\n",
    "</blockquote>\n",
    "\n",
    "The [final post](http://aagenielsen.dk/hnefataflforum/phpBB3/viewtopic.php?f=1&t=112&start=10) in a spirited forum discussion about repetitions and vaguery in the Copenhagen rules ended:\n",
    "<blockquote>\n",
    "\"October 2020 Adam Bartley started a discussion with Mario Aluizo (\"casshern\") and myself about repetitions in Tafl, and we came to the conclusion that the repetitions rule can be simplified, so that repetitions are always a loss for white (the defenders).\n",
    "\n",
    "I searched the full archive ten years for games ending in black repetitions and found none.\n",
    "\n",
    "Repetitions being always a loss for white has also earlier been suggested by Ytreza, Nath, OdinHimself and Unhandyandy.\n",
    "\n",
    "So the repetitions rule will be:\n",
    "Rule 8: Any perpetual repetition results in a loss for white.\"\n",
    "</blockquote>\n",
    "\n",
    "I am thankful for this clarification in the blog, as the wording *\"the player in control of the situation\"* gave me a shiver down my spine. So even though there is a lack of clarity here -what constitutes a *perpetual* repetition- I'll make my own interpretation for training which I think the forum mods would be incomfortable with, and copy chess's 3-fold repetition rule. Those guys knew what they were doing. \n",
    "\n",
    "I will follow the chess approach of 'counting' unique positons, most likely via Zobrist hashing to generate keys. Initially I thought to only track the last few moves and see if they were directly repetitive (two pieces moving back and forth across two squares), but this ignores the possibility of a multi-piece repetitive sequence. The issue with a chess-like approach is this could lead to losses for White in circumstances where the player could reasonably feel that she is 'sniffing out' an exit with long sequences of non-repetitive moves that circle back to the same positions. However, the piece mobility and space involved in the game, combined with the inherent asymmetry, makes me believe that the vast majority of repetition occurances would be short-sequence shuffles with the King or White, moving away from, or protecting against, capture by Black. In cases where White is 'in control of the situation', by which I read, 'is leading the repetitive sequence', they will hopefully avoid repetitive moves once the Neural Net learns the associated penalties. And the Monte Carlo Tree Search approach will penalize branches associated with these instances in any case.\n",
    "\n",
    "Because the vast majority of repetitions will be quickfire, I will store the previous 7 board positions and pass these into the model. Doing this will have the oddity of needing Black to 'accept' the draw by making the last repeated move to win, when the move-1 by White is essentially an invitation for Black to end the game so should strictly be the last move. I don't see an elegant way around this while keeping the engine resilient to multi-sequence repetitions. AlphaZero and Lc0 both used past board positions in part to flag repetiitions, and it may well help the model recognise patterns during training as suggested by Klein in Neural Networks for Chess. This topic has been dfiscussed at length on the Lc0 message boards in more online community spirited debate. In principle, I understand the skeptic's angle that the game state should be Markovian, 8 states alone are not guaranteed to capture the details of repetition, and MCTS should deal entirely with the issues of reptition avoidance / encouragement. However, some of the arguments laid out in favour of history planes are convincing enough, and one of the Lc0 devs made clear that history inclusion definitively improved performance in some observed cases. Additionally, when dealing with such deep networks, additional input planes are very cheap, so any information that will help the Network learn should certainly be included. For example, out of curiosity I constructed my initial model (pending change) with both (8, 9, 9) and (57, 9, 9) input shapes, and the number of trainiable parameters only increased from 3,309,044 to 3,365,492. Fascinating!\n",
    "\n",
    "__Returning to Input Format:__\n",
    "\n",
    "As explained above, we describe our board with a 4x 9x9 tensor. To encode repetitions, we'll add 1 more plane as a repitition counter - this will be all 1s if the position has already appeared else 0s. The 6th plane will mark the player's turn - full of Zeros for Black and Ones for White. This gives us a (6, 9, 9) shape, which we will stack the previous 7 moves onto for a total of (48, 9, 9). I am still not sure that including history is the best move - clearly in practice this had led to improved performance, but it introduces complications (introducing a hash system, etc) that I have never dealt with before. Maybe that alone is good enough reason to try. One last thought that I'd had was including a plane of Board Edges, as they are special squares for win conditions. However, I think that there is a chance that this would 'overweigh' these areas of the board, and the approach of dilineating important areas as constants hasn't been used elsewhere that I can see. One common approach that I am adopting is the inclusion of a constant plane of 1s in the input - this will help the network distinguish the boundaries of the board during convolutions. This results in a final input shape of (49, 9, 9) as broken down in the image below:\n",
    "\n",
    "![](/Users/peterbitman/Desktop/tafl/muninn/tablut/tablut_tensor.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step: Basic Gameplay\n",
    "\n",
    "This just ensures that I can create a board, and move  pieces around on it. We'll create a class for the Board, complete with sensible constants, and methods for basic game mechanics. Then I want to depart from my proof of concept structure and take advantage of a more fleshy 'play game' class that includes all of the legwork necessary for feeding into the MCTS / CNN pipeline. Eventually I will create other classes to handle gameplay between human agents and the model, and among models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import numpy as np\n",
    "import time\n",
    "import timeit\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(0, 0), (0, 1)': 0, '(0, 0), (1, 0)': 1, '(0, 0), (0, 2)': 2, '(0, 0), (2, 0)': 3, '(0, 0), (0, 3)': 4, '(0, 0), (3, 0)': 5, '(0, 0), (0, 4)': 6, '(0, 0), (4, 0)': 7, '(0, 0), (0, 5)': 8, '(0, 0), (5, 0)': 9, '(0, 0), (0, 6)': 10, '(0, 0), (6, 0)': 11, '(0, 0), (0, 7)': 12, '(0, 0), (7, 0)': 13, '(0, 0), (0, 8)': 14, '(0, 0), (8, 0)': 15, '(0, 1), (0, 0)': 16, '(0, 1), (1, 1)': 17, '(0, 1), (0, 2)': 18, '(0, 1), (2, 1)': 19, '(0, 1), (0, 3)': 20, '(0, 1), (3, 1)': 21, '(0, 1), (0, 4)': 22, '(0, 1), (4, 1)': 23, '(0, 1), (0, 5)': 24, '(0, 1), (5, 1)': 25, '(0, 1), (0, 6)': 26, '(0, 1), (6, 1)': 27, '(0, 1), (0, 7)': 28, '(0, 1), (7, 1)': 29, '(0, 1), (0, 8)': 30, '(0, 1), (8, 1)': 31, '(0, 2), (0, 0)': 32, '(0, 2), (0, 1)': 33, '(0, 2), (1, 2)': 34, '(0, 2), (2, 2)': 35, '(0, 2), (0, 3)': 36, '(0, 2), (3, 2)': 37, '(0, 2), (0, 4)': 38, '(0, 2), (4, 2)': 39, '(0, 2), (0, 5)': 40, '(0, 2), (5, 2)': 41, '(0, 2), (0, 6)': 42, '(0, 2), (6, 2)': 43, '(0, 2), (0, 7)': 44, '(0, 2), (7, 2)': 45, '(0, 2), (0, 8)': 46, '(0, 2), (8, 2)': 47, '(0, 3), (0, 0)': 48, '(0, 3), (0, 1)': 49, '(0, 3), (1, 3)': 50, '(0, 3), (0, 2)': 51, '(0, 3), (2, 3)': 52, '(0, 3), (3, 3)': 53, '(0, 3), (0, 4)': 54, '(0, 3), (4, 3)': 55, '(0, 3), (0, 5)': 56, '(0, 3), (5, 3)': 57, '(0, 3), (0, 6)': 58, '(0, 3), (6, 3)': 59, '(0, 3), (0, 7)': 60, '(0, 3), (7, 3)': 61, '(0, 3), (0, 8)': 62, '(0, 3), (8, 3)': 63, '(0, 4), (0, 0)': 64, '(0, 4), (0, 1)': 65, '(0, 4), (1, 4)': 66, '(0, 4), (0, 2)': 67, '(0, 4), (2, 4)': 68, '(0, 4), (0, 3)': 69, '(0, 4), (3, 4)': 70, '(0, 4), (4, 4)': 71, '(0, 4), (0, 5)': 72, '(0, 4), (5, 4)': 73, '(0, 4), (0, 6)': 74, '(0, 4), (6, 4)': 75, '(0, 4), (0, 7)': 76, '(0, 4), (7, 4)': 77, '(0, 4), (0, 8)': 78, '(0, 4), (8, 4)': 79, '(0, 5), (0, 0)': 80, '(0, 5), (0, 1)': 81, '(0, 5), (1, 5)': 82, '(0, 5), (0, 2)': 83, '(0, 5), (2, 5)': 84, '(0, 5), (0, 3)': 85, '(0, 5), (3, 5)': 86, '(0, 5), (0, 4)': 87, '(0, 5), (4, 5)': 88, '(0, 5), (5, 5)': 89, '(0, 5), (0, 6)': 90, '(0, 5), (6, 5)': 91, '(0, 5), (0, 7)': 92, '(0, 5), (7, 5)': 93, '(0, 5), (0, 8)': 94, '(0, 5), (8, 5)': 95, '(0, 6), (0, 0)': 96, '(0, 6), (0, 1)': 97, '(0, 6), (1, 6)': 98, '(0, 6), (0, 2)': 99, '(0, 6), (2, 6)': 100, '(0, 6), (0, 3)': 101, '(0, 6), (3, 6)': 102, '(0, 6), (0, 4)': 103, '(0, 6), (4, 6)': 104, '(0, 6), (0, 5)': 105, '(0, 6), (5, 6)': 106, '(0, 6), (6, 6)': 107, '(0, 6), (0, 7)': 108, '(0, 6), (7, 6)': 109, '(0, 6), (0, 8)': 110, '(0, 6), (8, 6)': 111, '(0, 7), (0, 0)': 112, '(0, 7), (0, 1)': 113, '(0, 7), (1, 7)': 114, '(0, 7), (0, 2)': 115, '(0, 7), (2, 7)': 116, '(0, 7), (0, 3)': 117, '(0, 7), (3, 7)': 118, '(0, 7), (0, 4)': 119, '(0, 7), (4, 7)': 120, '(0, 7), (0, 5)': 121, '(0, 7), (5, 7)': 122, '(0, 7), (0, 6)': 123, '(0, 7), (6, 7)': 124, '(0, 7), (7, 7)': 125, '(0, 7), (0, 8)': 126, '(0, 7), (8, 7)': 127, '(0, 8), (0, 0)': 128, '(0, 8), (0, 1)': 129, '(0, 8), (1, 8)': 130, '(0, 8), (0, 2)': 131, '(0, 8), (2, 8)': 132, '(0, 8), (0, 3)': 133, '(0, 8), (3, 8)': 134, '(0, 8), (0, 4)': 135, '(0, 8), (4, 8)': 136, '(0, 8), (0, 5)': 137, '(0, 8), (5, 8)': 138, '(0, 8), (0, 6)': 139, '(0, 8), (6, 8)': 140, '(0, 8), (0, 7)': 141, '(0, 8), (7, 8)': 142, '(0, 8), (8, 8)': 143, '(1, 0), (0, 0)': 144, '(1, 0), (1, 1)': 145, '(1, 0), (1, 2)': 146, '(1, 0), (2, 0)': 147, '(1, 0), (1, 3)': 148, '(1, 0), (3, 0)': 149, '(1, 0), (1, 4)': 150, '(1, 0), (4, 0)': 151, '(1, 0), (1, 5)': 152, '(1, 0), (5, 0)': 153, '(1, 0), (1, 6)': 154, '(1, 0), (6, 0)': 155, '(1, 0), (1, 7)': 156, '(1, 0), (7, 0)': 157, '(1, 0), (1, 8)': 158, '(1, 0), (8, 0)': 159, '(1, 1), (1, 0)': 160, '(1, 1), (0, 1)': 161, '(1, 1), (1, 2)': 162, '(1, 1), (2, 1)': 163, '(1, 1), (1, 3)': 164, '(1, 1), (3, 1)': 165, '(1, 1), (1, 4)': 166, '(1, 1), (4, 1)': 167, '(1, 1), (1, 5)': 168, '(1, 1), (5, 1)': 169, '(1, 1), (1, 6)': 170, '(1, 1), (6, 1)': 171, '(1, 1), (1, 7)': 172, '(1, 1), (7, 1)': 173, '(1, 1), (1, 8)': 174, '(1, 1), (8, 1)': 175, '(1, 2), (1, 0)': 176, '(1, 2), (0, 2)': 177, '(1, 2), (1, 1)': 178, '(1, 2), (2, 2)': 179, '(1, 2), (1, 3)': 180, '(1, 2), (3, 2)': 181, '(1, 2), (1, 4)': 182, '(1, 2), (4, 2)': 183, '(1, 2), (1, 5)': 184, '(1, 2), (5, 2)': 185, '(1, 2), (1, 6)': 186, '(1, 2), (6, 2)': 187, '(1, 2), (1, 7)': 188, '(1, 2), (7, 2)': 189, '(1, 2), (1, 8)': 190, '(1, 2), (8, 2)': 191, '(1, 3), (1, 0)': 192, '(1, 3), (0, 3)': 193, '(1, 3), (1, 1)': 194, '(1, 3), (1, 2)': 195, '(1, 3), (2, 3)': 196, '(1, 3), (3, 3)': 197, '(1, 3), (1, 4)': 198, '(1, 3), (4, 3)': 199, '(1, 3), (1, 5)': 200, '(1, 3), (5, 3)': 201, '(1, 3), (1, 6)': 202, '(1, 3), (6, 3)': 203, '(1, 3), (1, 7)': 204, '(1, 3), (7, 3)': 205, '(1, 3), (1, 8)': 206, '(1, 3), (8, 3)': 207, '(1, 4), (1, 0)': 208, '(1, 4), (0, 4)': 209, '(1, 4), (1, 1)': 210, '(1, 4), (1, 2)': 211, '(1, 4), (2, 4)': 212, '(1, 4), (1, 3)': 213, '(1, 4), (3, 4)': 214, '(1, 4), (4, 4)': 215, '(1, 4), (1, 5)': 216, '(1, 4), (5, 4)': 217, '(1, 4), (1, 6)': 218, '(1, 4), (6, 4)': 219, '(1, 4), (1, 7)': 220, '(1, 4), (7, 4)': 221, '(1, 4), (1, 8)': 222, '(1, 4), (8, 4)': 223, '(1, 5), (1, 0)': 224, '(1, 5), (0, 5)': 225, '(1, 5), (1, 1)': 226, '(1, 5), (1, 2)': 227, '(1, 5), (2, 5)': 228, '(1, 5), (1, 3)': 229, '(1, 5), (3, 5)': 230, '(1, 5), (1, 4)': 231, '(1, 5), (4, 5)': 232, '(1, 5), (5, 5)': 233, '(1, 5), (1, 6)': 234, '(1, 5), (6, 5)': 235, '(1, 5), (1, 7)': 236, '(1, 5), (7, 5)': 237, '(1, 5), (1, 8)': 238, '(1, 5), (8, 5)': 239, '(1, 6), (1, 0)': 240, '(1, 6), (0, 6)': 241, '(1, 6), (1, 1)': 242, '(1, 6), (1, 2)': 243, '(1, 6), (2, 6)': 244, '(1, 6), (1, 3)': 245, '(1, 6), (3, 6)': 246, '(1, 6), (1, 4)': 247, '(1, 6), (4, 6)': 248, '(1, 6), (1, 5)': 249, '(1, 6), (5, 6)': 250, '(1, 6), (6, 6)': 251, '(1, 6), (1, 7)': 252, '(1, 6), (7, 6)': 253, '(1, 6), (1, 8)': 254, '(1, 6), (8, 6)': 255, '(1, 7), (1, 0)': 256, '(1, 7), (0, 7)': 257, '(1, 7), (1, 1)': 258, '(1, 7), (1, 2)': 259, '(1, 7), (2, 7)': 260, '(1, 7), (1, 3)': 261, '(1, 7), (3, 7)': 262, '(1, 7), (1, 4)': 263, '(1, 7), (4, 7)': 264, '(1, 7), (1, 5)': 265, '(1, 7), (5, 7)': 266, '(1, 7), (1, 6)': 267, '(1, 7), (6, 7)': 268, '(1, 7), (7, 7)': 269, '(1, 7), (1, 8)': 270, '(1, 7), (8, 7)': 271, '(1, 8), (1, 0)': 272, '(1, 8), (0, 8)': 273, '(1, 8), (1, 1)': 274, '(1, 8), (1, 2)': 275, '(1, 8), (2, 8)': 276, '(1, 8), (1, 3)': 277, '(1, 8), (3, 8)': 278, '(1, 8), (1, 4)': 279, '(1, 8), (4, 8)': 280, '(1, 8), (1, 5)': 281, '(1, 8), (5, 8)': 282, '(1, 8), (1, 6)': 283, '(1, 8), (6, 8)': 284, '(1, 8), (1, 7)': 285, '(1, 8), (7, 8)': 286, '(1, 8), (8, 8)': 287, '(2, 0), (0, 0)': 288, '(2, 0), (2, 1)': 289, '(2, 0), (1, 0)': 290, '(2, 0), (2, 2)': 291, '(2, 0), (2, 3)': 292, '(2, 0), (3, 0)': 293, '(2, 0), (2, 4)': 294, '(2, 0), (4, 0)': 295, '(2, 0), (2, 5)': 296, '(2, 0), (5, 0)': 297, '(2, 0), (2, 6)': 298, '(2, 0), (6, 0)': 299, '(2, 0), (2, 7)': 300, '(2, 0), (7, 0)': 301, '(2, 0), (2, 8)': 302, '(2, 0), (8, 0)': 303, '(2, 1), (2, 0)': 304, '(2, 1), (0, 1)': 305, '(2, 1), (1, 1)': 306, '(2, 1), (2, 2)': 307, '(2, 1), (2, 3)': 308, '(2, 1), (3, 1)': 309, '(2, 1), (2, 4)': 310, '(2, 1), (4, 1)': 311, '(2, 1), (2, 5)': 312, '(2, 1), (5, 1)': 313, '(2, 1), (2, 6)': 314, '(2, 1), (6, 1)': 315, '(2, 1), (2, 7)': 316, '(2, 1), (7, 1)': 317, '(2, 1), (2, 8)': 318, '(2, 1), (8, 1)': 319, '(2, 2), (2, 0)': 320, '(2, 2), (0, 2)': 321, '(2, 2), (2, 1)': 322, '(2, 2), (1, 2)': 323, '(2, 2), (2, 3)': 324, '(2, 2), (3, 2)': 325, '(2, 2), (2, 4)': 326, '(2, 2), (4, 2)': 327, '(2, 2), (2, 5)': 328, '(2, 2), (5, 2)': 329, '(2, 2), (2, 6)': 330, '(2, 2), (6, 2)': 331, '(2, 2), (2, 7)': 332, '(2, 2), (7, 2)': 333, '(2, 2), (2, 8)': 334, '(2, 2), (8, 2)': 335, '(2, 3), (2, 0)': 336, '(2, 3), (0, 3)': 337, '(2, 3), (2, 1)': 338, '(2, 3), (1, 3)': 339, '(2, 3), (2, 2)': 340, '(2, 3), (3, 3)': 341, '(2, 3), (2, 4)': 342, '(2, 3), (4, 3)': 343, '(2, 3), (2, 5)': 344, '(2, 3), (5, 3)': 345, '(2, 3), (2, 6)': 346, '(2, 3), (6, 3)': 347, '(2, 3), (2, 7)': 348, '(2, 3), (7, 3)': 349, '(2, 3), (2, 8)': 350, '(2, 3), (8, 3)': 351, '(2, 4), (2, 0)': 352, '(2, 4), (0, 4)': 353, '(2, 4), (2, 1)': 354, '(2, 4), (1, 4)': 355, '(2, 4), (2, 2)': 356, '(2, 4), (2, 3)': 357, '(2, 4), (3, 4)': 358, '(2, 4), (4, 4)': 359, '(2, 4), (2, 5)': 360, '(2, 4), (5, 4)': 361, '(2, 4), (2, 6)': 362, '(2, 4), (6, 4)': 363, '(2, 4), (2, 7)': 364, '(2, 4), (7, 4)': 365, '(2, 4), (2, 8)': 366, '(2, 4), (8, 4)': 367, '(2, 5), (2, 0)': 368, '(2, 5), (0, 5)': 369, '(2, 5), (2, 1)': 370, '(2, 5), (1, 5)': 371, '(2, 5), (2, 2)': 372, '(2, 5), (2, 3)': 373, '(2, 5), (3, 5)': 374, '(2, 5), (2, 4)': 375, '(2, 5), (4, 5)': 376, '(2, 5), (5, 5)': 377, '(2, 5), (2, 6)': 378, '(2, 5), (6, 5)': 379, '(2, 5), (2, 7)': 380, '(2, 5), (7, 5)': 381, '(2, 5), (2, 8)': 382, '(2, 5), (8, 5)': 383, '(2, 6), (2, 0)': 384, '(2, 6), (0, 6)': 385, '(2, 6), (2, 1)': 386, '(2, 6), (1, 6)': 387, '(2, 6), (2, 2)': 388, '(2, 6), (2, 3)': 389, '(2, 6), (3, 6)': 390, '(2, 6), (2, 4)': 391, '(2, 6), (4, 6)': 392, '(2, 6), (2, 5)': 393, '(2, 6), (5, 6)': 394, '(2, 6), (6, 6)': 395, '(2, 6), (2, 7)': 396, '(2, 6), (7, 6)': 397, '(2, 6), (2, 8)': 398, '(2, 6), (8, 6)': 399, '(2, 7), (2, 0)': 400, '(2, 7), (0, 7)': 401, '(2, 7), (2, 1)': 402, '(2, 7), (1, 7)': 403, '(2, 7), (2, 2)': 404, '(2, 7), (2, 3)': 405, '(2, 7), (3, 7)': 406, '(2, 7), (2, 4)': 407, '(2, 7), (4, 7)': 408, '(2, 7), (2, 5)': 409, '(2, 7), (5, 7)': 410, '(2, 7), (2, 6)': 411, '(2, 7), (6, 7)': 412, '(2, 7), (7, 7)': 413, '(2, 7), (2, 8)': 414, '(2, 7), (8, 7)': 415, '(2, 8), (2, 0)': 416, '(2, 8), (0, 8)': 417, '(2, 8), (2, 1)': 418, '(2, 8), (1, 8)': 419, '(2, 8), (2, 2)': 420, '(2, 8), (2, 3)': 421, '(2, 8), (3, 8)': 422, '(2, 8), (2, 4)': 423, '(2, 8), (4, 8)': 424, '(2, 8), (2, 5)': 425, '(2, 8), (5, 8)': 426, '(2, 8), (2, 6)': 427, '(2, 8), (6, 8)': 428, '(2, 8), (2, 7)': 429, '(2, 8), (7, 8)': 430, '(2, 8), (8, 8)': 431, '(3, 0), (0, 0)': 432, '(3, 0), (3, 1)': 433, '(3, 0), (1, 0)': 434, '(3, 0), (3, 2)': 435, '(3, 0), (2, 0)': 436, '(3, 0), (3, 3)': 437, '(3, 0), (3, 4)': 438, '(3, 0), (4, 0)': 439, '(3, 0), (3, 5)': 440, '(3, 0), (5, 0)': 441, '(3, 0), (3, 6)': 442, '(3, 0), (6, 0)': 443, '(3, 0), (3, 7)': 444, '(3, 0), (7, 0)': 445, '(3, 0), (3, 8)': 446, '(3, 0), (8, 0)': 447, '(3, 1), (3, 0)': 448, '(3, 1), (0, 1)': 449, '(3, 1), (1, 1)': 450, '(3, 1), (3, 2)': 451, '(3, 1), (2, 1)': 452, '(3, 1), (3, 3)': 453, '(3, 1), (3, 4)': 454, '(3, 1), (4, 1)': 455, '(3, 1), (3, 5)': 456, '(3, 1), (5, 1)': 457, '(3, 1), (3, 6)': 458, '(3, 1), (6, 1)': 459, '(3, 1), (3, 7)': 460, '(3, 1), (7, 1)': 461, '(3, 1), (3, 8)': 462, '(3, 1), (8, 1)': 463, '(3, 2), (3, 0)': 464, '(3, 2), (0, 2)': 465, '(3, 2), (3, 1)': 466, '(3, 2), (1, 2)': 467, '(3, 2), (2, 2)': 468, '(3, 2), (3, 3)': 469, '(3, 2), (3, 4)': 470, '(3, 2), (4, 2)': 471, '(3, 2), (3, 5)': 472, '(3, 2), (5, 2)': 473, '(3, 2), (3, 6)': 474, '(3, 2), (6, 2)': 475, '(3, 2), (3, 7)': 476, '(3, 2), (7, 2)': 477, '(3, 2), (3, 8)': 478, '(3, 2), (8, 2)': 479, '(3, 3), (3, 0)': 480, '(3, 3), (0, 3)': 481, '(3, 3), (3, 1)': 482, '(3, 3), (1, 3)': 483, '(3, 3), (3, 2)': 484, '(3, 3), (2, 3)': 485, '(3, 3), (3, 4)': 486, '(3, 3), (4, 3)': 487, '(3, 3), (3, 5)': 488, '(3, 3), (5, 3)': 489, '(3, 3), (3, 6)': 490, '(3, 3), (6, 3)': 491, '(3, 3), (3, 7)': 492, '(3, 3), (7, 3)': 493, '(3, 3), (3, 8)': 494, '(3, 3), (8, 3)': 495, '(3, 4), (3, 0)': 496, '(3, 4), (0, 4)': 497, '(3, 4), (3, 1)': 498, '(3, 4), (1, 4)': 499, '(3, 4), (3, 2)': 500, '(3, 4), (2, 4)': 501, '(3, 4), (3, 3)': 502, '(3, 4), (4, 4)': 503, '(3, 4), (3, 5)': 504, '(3, 4), (5, 4)': 505, '(3, 4), (3, 6)': 506, '(3, 4), (6, 4)': 507, '(3, 4), (3, 7)': 508, '(3, 4), (7, 4)': 509, '(3, 4), (3, 8)': 510, '(3, 4), (8, 4)': 511, '(3, 5), (3, 0)': 512, '(3, 5), (0, 5)': 513, '(3, 5), (3, 1)': 514, '(3, 5), (1, 5)': 515, '(3, 5), (3, 2)': 516, '(3, 5), (2, 5)': 517, '(3, 5), (3, 3)': 518, '(3, 5), (3, 4)': 519, '(3, 5), (4, 5)': 520, '(3, 5), (5, 5)': 521, '(3, 5), (3, 6)': 522, '(3, 5), (6, 5)': 523, '(3, 5), (3, 7)': 524, '(3, 5), (7, 5)': 525, '(3, 5), (3, 8)': 526, '(3, 5), (8, 5)': 527, '(3, 6), (3, 0)': 528, '(3, 6), (0, 6)': 529, '(3, 6), (3, 1)': 530, '(3, 6), (1, 6)': 531, '(3, 6), (3, 2)': 532, '(3, 6), (2, 6)': 533, '(3, 6), (3, 3)': 534, '(3, 6), (3, 4)': 535, '(3, 6), (4, 6)': 536, '(3, 6), (3, 5)': 537, '(3, 6), (5, 6)': 538, '(3, 6), (6, 6)': 539, '(3, 6), (3, 7)': 540, '(3, 6), (7, 6)': 541, '(3, 6), (3, 8)': 542, '(3, 6), (8, 6)': 543, '(3, 7), (3, 0)': 544, '(3, 7), (0, 7)': 545, '(3, 7), (3, 1)': 546, '(3, 7), (1, 7)': 547, '(3, 7), (3, 2)': 548, '(3, 7), (2, 7)': 549, '(3, 7), (3, 3)': 550, '(3, 7), (3, 4)': 551, '(3, 7), (4, 7)': 552, '(3, 7), (3, 5)': 553, '(3, 7), (5, 7)': 554, '(3, 7), (3, 6)': 555, '(3, 7), (6, 7)': 556, '(3, 7), (7, 7)': 557, '(3, 7), (3, 8)': 558, '(3, 7), (8, 7)': 559, '(3, 8), (3, 0)': 560, '(3, 8), (0, 8)': 561, '(3, 8), (3, 1)': 562, '(3, 8), (1, 8)': 563, '(3, 8), (3, 2)': 564, '(3, 8), (2, 8)': 565, '(3, 8), (3, 3)': 566, '(3, 8), (3, 4)': 567, '(3, 8), (4, 8)': 568, '(3, 8), (3, 5)': 569, '(3, 8), (5, 8)': 570, '(3, 8), (3, 6)': 571, '(3, 8), (6, 8)': 572, '(3, 8), (3, 7)': 573, '(3, 8), (7, 8)': 574, '(3, 8), (8, 8)': 575, '(4, 0), (0, 0)': 576, '(4, 0), (4, 1)': 577, '(4, 0), (1, 0)': 578, '(4, 0), (4, 2)': 579, '(4, 0), (2, 0)': 580, '(4, 0), (4, 3)': 581, '(4, 0), (3, 0)': 582, '(4, 0), (4, 4)': 583, '(4, 0), (4, 5)': 584, '(4, 0), (5, 0)': 585, '(4, 0), (4, 6)': 586, '(4, 0), (6, 0)': 587, '(4, 0), (4, 7)': 588, '(4, 0), (7, 0)': 589, '(4, 0), (4, 8)': 590, '(4, 0), (8, 0)': 591, '(4, 1), (4, 0)': 592, '(4, 1), (0, 1)': 593, '(4, 1), (1, 1)': 594, '(4, 1), (4, 2)': 595, '(4, 1), (2, 1)': 596, '(4, 1), (4, 3)': 597, '(4, 1), (3, 1)': 598, '(4, 1), (4, 4)': 599, '(4, 1), (4, 5)': 600, '(4, 1), (5, 1)': 601, '(4, 1), (4, 6)': 602, '(4, 1), (6, 1)': 603, '(4, 1), (4, 7)': 604, '(4, 1), (7, 1)': 605, '(4, 1), (4, 8)': 606, '(4, 1), (8, 1)': 607, '(4, 2), (4, 0)': 608, '(4, 2), (0, 2)': 609, '(4, 2), (4, 1)': 610, '(4, 2), (1, 2)': 611, '(4, 2), (2, 2)': 612, '(4, 2), (4, 3)': 613, '(4, 2), (3, 2)': 614, '(4, 2), (4, 4)': 615, '(4, 2), (4, 5)': 616, '(4, 2), (5, 2)': 617, '(4, 2), (4, 6)': 618, '(4, 2), (6, 2)': 619, '(4, 2), (4, 7)': 620, '(4, 2), (7, 2)': 621, '(4, 2), (4, 8)': 622, '(4, 2), (8, 2)': 623, '(4, 3), (4, 0)': 624, '(4, 3), (0, 3)': 625, '(4, 3), (4, 1)': 626, '(4, 3), (1, 3)': 627, '(4, 3), (4, 2)': 628, '(4, 3), (2, 3)': 629, '(4, 3), (3, 3)': 630, '(4, 3), (4, 4)': 631, '(4, 3), (4, 5)': 632, '(4, 3), (5, 3)': 633, '(4, 3), (4, 6)': 634, '(4, 3), (6, 3)': 635, '(4, 3), (4, 7)': 636, '(4, 3), (7, 3)': 637, '(4, 3), (4, 8)': 638, '(4, 3), (8, 3)': 639, '(4, 4), (4, 0)': 640, '(4, 4), (0, 4)': 641, '(4, 4), (4, 1)': 642, '(4, 4), (1, 4)': 643, '(4, 4), (4, 2)': 644, '(4, 4), (2, 4)': 645, '(4, 4), (4, 3)': 646, '(4, 4), (3, 4)': 647, '(4, 4), (4, 5)': 648, '(4, 4), (5, 4)': 649, '(4, 4), (4, 6)': 650, '(4, 4), (6, 4)': 651, '(4, 4), (4, 7)': 652, '(4, 4), (7, 4)': 653, '(4, 4), (4, 8)': 654, '(4, 4), (8, 4)': 655, '(4, 5), (4, 0)': 656, '(4, 5), (0, 5)': 657, '(4, 5), (4, 1)': 658, '(4, 5), (1, 5)': 659, '(4, 5), (4, 2)': 660, '(4, 5), (2, 5)': 661, '(4, 5), (4, 3)': 662, '(4, 5), (3, 5)': 663, '(4, 5), (4, 4)': 664, '(4, 5), (5, 5)': 665, '(4, 5), (4, 6)': 666, '(4, 5), (6, 5)': 667, '(4, 5), (4, 7)': 668, '(4, 5), (7, 5)': 669, '(4, 5), (4, 8)': 670, '(4, 5), (8, 5)': 671, '(4, 6), (4, 0)': 672, '(4, 6), (0, 6)': 673, '(4, 6), (4, 1)': 674, '(4, 6), (1, 6)': 675, '(4, 6), (4, 2)': 676, '(4, 6), (2, 6)': 677, '(4, 6), (4, 3)': 678, '(4, 6), (3, 6)': 679, '(4, 6), (4, 4)': 680, '(4, 6), (4, 5)': 681, '(4, 6), (5, 6)': 682, '(4, 6), (6, 6)': 683, '(4, 6), (4, 7)': 684, '(4, 6), (7, 6)': 685, '(4, 6), (4, 8)': 686, '(4, 6), (8, 6)': 687, '(4, 7), (4, 0)': 688, '(4, 7), (0, 7)': 689, '(4, 7), (4, 1)': 690, '(4, 7), (1, 7)': 691, '(4, 7), (4, 2)': 692, '(4, 7), (2, 7)': 693, '(4, 7), (4, 3)': 694, '(4, 7), (3, 7)': 695, '(4, 7), (4, 4)': 696, '(4, 7), (4, 5)': 697, '(4, 7), (5, 7)': 698, '(4, 7), (4, 6)': 699, '(4, 7), (6, 7)': 700, '(4, 7), (7, 7)': 701, '(4, 7), (4, 8)': 702, '(4, 7), (8, 7)': 703, '(4, 8), (4, 0)': 704, '(4, 8), (0, 8)': 705, '(4, 8), (4, 1)': 706, '(4, 8), (1, 8)': 707, '(4, 8), (4, 2)': 708, '(4, 8), (2, 8)': 709, '(4, 8), (4, 3)': 710, '(4, 8), (3, 8)': 711, '(4, 8), (4, 4)': 712, '(4, 8), (4, 5)': 713, '(4, 8), (5, 8)': 714, '(4, 8), (4, 6)': 715, '(4, 8), (6, 8)': 716, '(4, 8), (4, 7)': 717, '(4, 8), (7, 8)': 718, '(4, 8), (8, 8)': 719, '(5, 0), (0, 0)': 720, '(5, 0), (5, 1)': 721, '(5, 0), (1, 0)': 722, '(5, 0), (5, 2)': 723, '(5, 0), (2, 0)': 724, '(5, 0), (5, 3)': 725, '(5, 0), (3, 0)': 726, '(5, 0), (5, 4)': 727, '(5, 0), (4, 0)': 728, '(5, 0), (5, 5)': 729, '(5, 0), (5, 6)': 730, '(5, 0), (6, 0)': 731, '(5, 0), (5, 7)': 732, '(5, 0), (7, 0)': 733, '(5, 0), (5, 8)': 734, '(5, 0), (8, 0)': 735, '(5, 1), (5, 0)': 736, '(5, 1), (0, 1)': 737, '(5, 1), (1, 1)': 738, '(5, 1), (5, 2)': 739, '(5, 1), (2, 1)': 740, '(5, 1), (5, 3)': 741, '(5, 1), (3, 1)': 742, '(5, 1), (5, 4)': 743, '(5, 1), (4, 1)': 744, '(5, 1), (5, 5)': 745, '(5, 1), (5, 6)': 746, '(5, 1), (6, 1)': 747, '(5, 1), (5, 7)': 748, '(5, 1), (7, 1)': 749, '(5, 1), (5, 8)': 750, '(5, 1), (8, 1)': 751, '(5, 2), (5, 0)': 752, '(5, 2), (0, 2)': 753, '(5, 2), (5, 1)': 754, '(5, 2), (1, 2)': 755, '(5, 2), (2, 2)': 756, '(5, 2), (5, 3)': 757, '(5, 2), (3, 2)': 758, '(5, 2), (5, 4)': 759, '(5, 2), (4, 2)': 760, '(5, 2), (5, 5)': 761, '(5, 2), (5, 6)': 762, '(5, 2), (6, 2)': 763, '(5, 2), (5, 7)': 764, '(5, 2), (7, 2)': 765, '(5, 2), (5, 8)': 766, '(5, 2), (8, 2)': 767, '(5, 3), (5, 0)': 768, '(5, 3), (0, 3)': 769, '(5, 3), (5, 1)': 770, '(5, 3), (1, 3)': 771, '(5, 3), (5, 2)': 772, '(5, 3), (2, 3)': 773, '(5, 3), (3, 3)': 774, '(5, 3), (5, 4)': 775, '(5, 3), (4, 3)': 776, '(5, 3), (5, 5)': 777, '(5, 3), (5, 6)': 778, '(5, 3), (6, 3)': 779, '(5, 3), (5, 7)': 780, '(5, 3), (7, 3)': 781, '(5, 3), (5, 8)': 782, '(5, 3), (8, 3)': 783, '(5, 4), (5, 0)': 784, '(5, 4), (0, 4)': 785, '(5, 4), (5, 1)': 786, '(5, 4), (1, 4)': 787, '(5, 4), (5, 2)': 788, '(5, 4), (2, 4)': 789, '(5, 4), (5, 3)': 790, '(5, 4), (3, 4)': 791, '(5, 4), (4, 4)': 792, '(5, 4), (5, 5)': 793, '(5, 4), (5, 6)': 794, '(5, 4), (6, 4)': 795, '(5, 4), (5, 7)': 796, '(5, 4), (7, 4)': 797, '(5, 4), (5, 8)': 798, '(5, 4), (8, 4)': 799, '(5, 5), (5, 0)': 800, '(5, 5), (0, 5)': 801, '(5, 5), (5, 1)': 802, '(5, 5), (1, 5)': 803, '(5, 5), (5, 2)': 804, '(5, 5), (2, 5)': 805, '(5, 5), (5, 3)': 806, '(5, 5), (3, 5)': 807, '(5, 5), (5, 4)': 808, '(5, 5), (4, 5)': 809, '(5, 5), (5, 6)': 810, '(5, 5), (6, 5)': 811, '(5, 5), (5, 7)': 812, '(5, 5), (7, 5)': 813, '(5, 5), (5, 8)': 814, '(5, 5), (8, 5)': 815, '(5, 6), (5, 0)': 816, '(5, 6), (0, 6)': 817, '(5, 6), (5, 1)': 818, '(5, 6), (1, 6)': 819, '(5, 6), (5, 2)': 820, '(5, 6), (2, 6)': 821, '(5, 6), (5, 3)': 822, '(5, 6), (3, 6)': 823, '(5, 6), (5, 4)': 824, '(5, 6), (4, 6)': 825, '(5, 6), (5, 5)': 826, '(5, 6), (6, 6)': 827, '(5, 6), (5, 7)': 828, '(5, 6), (7, 6)': 829, '(5, 6), (5, 8)': 830, '(5, 6), (8, 6)': 831, '(5, 7), (5, 0)': 832, '(5, 7), (0, 7)': 833, '(5, 7), (5, 1)': 834, '(5, 7), (1, 7)': 835, '(5, 7), (5, 2)': 836, '(5, 7), (2, 7)': 837, '(5, 7), (5, 3)': 838, '(5, 7), (3, 7)': 839, '(5, 7), (5, 4)': 840, '(5, 7), (4, 7)': 841, '(5, 7), (5, 5)': 842, '(5, 7), (5, 6)': 843, '(5, 7), (6, 7)': 844, '(5, 7), (7, 7)': 845, '(5, 7), (5, 8)': 846, '(5, 7), (8, 7)': 847, '(5, 8), (5, 0)': 848, '(5, 8), (0, 8)': 849, '(5, 8), (5, 1)': 850, '(5, 8), (1, 8)': 851, '(5, 8), (5, 2)': 852, '(5, 8), (2, 8)': 853, '(5, 8), (5, 3)': 854, '(5, 8), (3, 8)': 855, '(5, 8), (5, 4)': 856, '(5, 8), (4, 8)': 857, '(5, 8), (5, 5)': 858, '(5, 8), (5, 6)': 859, '(5, 8), (6, 8)': 860, '(5, 8), (5, 7)': 861, '(5, 8), (7, 8)': 862, '(5, 8), (8, 8)': 863, '(6, 0), (0, 0)': 864, '(6, 0), (6, 1)': 865, '(6, 0), (1, 0)': 866, '(6, 0), (6, 2)': 867, '(6, 0), (2, 0)': 868, '(6, 0), (6, 3)': 869, '(6, 0), (3, 0)': 870, '(6, 0), (6, 4)': 871, '(6, 0), (4, 0)': 872, '(6, 0), (6, 5)': 873, '(6, 0), (5, 0)': 874, '(6, 0), (6, 6)': 875, '(6, 0), (6, 7)': 876, '(6, 0), (7, 0)': 877, '(6, 0), (6, 8)': 878, '(6, 0), (8, 0)': 879, '(6, 1), (6, 0)': 880, '(6, 1), (0, 1)': 881, '(6, 1), (1, 1)': 882, '(6, 1), (6, 2)': 883, '(6, 1), (2, 1)': 884, '(6, 1), (6, 3)': 885, '(6, 1), (3, 1)': 886, '(6, 1), (6, 4)': 887, '(6, 1), (4, 1)': 888, '(6, 1), (6, 5)': 889, '(6, 1), (5, 1)': 890, '(6, 1), (6, 6)': 891, '(6, 1), (6, 7)': 892, '(6, 1), (7, 1)': 893, '(6, 1), (6, 8)': 894, '(6, 1), (8, 1)': 895, '(6, 2), (6, 0)': 896, '(6, 2), (0, 2)': 897, '(6, 2), (6, 1)': 898, '(6, 2), (1, 2)': 899, '(6, 2), (2, 2)': 900, '(6, 2), (6, 3)': 901, '(6, 2), (3, 2)': 902, '(6, 2), (6, 4)': 903, '(6, 2), (4, 2)': 904, '(6, 2), (6, 5)': 905, '(6, 2), (5, 2)': 906, '(6, 2), (6, 6)': 907, '(6, 2), (6, 7)': 908, '(6, 2), (7, 2)': 909, '(6, 2), (6, 8)': 910, '(6, 2), (8, 2)': 911, '(6, 3), (6, 0)': 912, '(6, 3), (0, 3)': 913, '(6, 3), (6, 1)': 914, '(6, 3), (1, 3)': 915, '(6, 3), (6, 2)': 916, '(6, 3), (2, 3)': 917, '(6, 3), (3, 3)': 918, '(6, 3), (6, 4)': 919, '(6, 3), (4, 3)': 920, '(6, 3), (6, 5)': 921, '(6, 3), (5, 3)': 922, '(6, 3), (6, 6)': 923, '(6, 3), (6, 7)': 924, '(6, 3), (7, 3)': 925, '(6, 3), (6, 8)': 926, '(6, 3), (8, 3)': 927, '(6, 4), (6, 0)': 928, '(6, 4), (0, 4)': 929, '(6, 4), (6, 1)': 930, '(6, 4), (1, 4)': 931, '(6, 4), (6, 2)': 932, '(6, 4), (2, 4)': 933, '(6, 4), (6, 3)': 934, '(6, 4), (3, 4)': 935, '(6, 4), (4, 4)': 936, '(6, 4), (6, 5)': 937, '(6, 4), (5, 4)': 938, '(6, 4), (6, 6)': 939, '(6, 4), (6, 7)': 940, '(6, 4), (7, 4)': 941, '(6, 4), (6, 8)': 942, '(6, 4), (8, 4)': 943, '(6, 5), (6, 0)': 944, '(6, 5), (0, 5)': 945, '(6, 5), (6, 1)': 946, '(6, 5), (1, 5)': 947, '(6, 5), (6, 2)': 948, '(6, 5), (2, 5)': 949, '(6, 5), (6, 3)': 950, '(6, 5), (3, 5)': 951, '(6, 5), (6, 4)': 952, '(6, 5), (4, 5)': 953, '(6, 5), (5, 5)': 954, '(6, 5), (6, 6)': 955, '(6, 5), (6, 7)': 956, '(6, 5), (7, 5)': 957, '(6, 5), (6, 8)': 958, '(6, 5), (8, 5)': 959, '(6, 6), (6, 0)': 960, '(6, 6), (0, 6)': 961, '(6, 6), (6, 1)': 962, '(6, 6), (1, 6)': 963, '(6, 6), (6, 2)': 964, '(6, 6), (2, 6)': 965, '(6, 6), (6, 3)': 966, '(6, 6), (3, 6)': 967, '(6, 6), (6, 4)': 968, '(6, 6), (4, 6)': 969, '(6, 6), (6, 5)': 970, '(6, 6), (5, 6)': 971, '(6, 6), (6, 7)': 972, '(6, 6), (7, 6)': 973, '(6, 6), (6, 8)': 974, '(6, 6), (8, 6)': 975, '(6, 7), (6, 0)': 976, '(6, 7), (0, 7)': 977, '(6, 7), (6, 1)': 978, '(6, 7), (1, 7)': 979, '(6, 7), (6, 2)': 980, '(6, 7), (2, 7)': 981, '(6, 7), (6, 3)': 982, '(6, 7), (3, 7)': 983, '(6, 7), (6, 4)': 984, '(6, 7), (4, 7)': 985, '(6, 7), (6, 5)': 986, '(6, 7), (5, 7)': 987, '(6, 7), (6, 6)': 988, '(6, 7), (7, 7)': 989, '(6, 7), (6, 8)': 990, '(6, 7), (8, 7)': 991, '(6, 8), (6, 0)': 992, '(6, 8), (0, 8)': 993, '(6, 8), (6, 1)': 994, '(6, 8), (1, 8)': 995, '(6, 8), (6, 2)': 996, '(6, 8), (2, 8)': 997, '(6, 8), (6, 3)': 998, '(6, 8), (3, 8)': 999, '(6, 8), (6, 4)': 1000, '(6, 8), (4, 8)': 1001, '(6, 8), (6, 5)': 1002, '(6, 8), (5, 8)': 1003, '(6, 8), (6, 6)': 1004, '(6, 8), (6, 7)': 1005, '(6, 8), (7, 8)': 1006, '(6, 8), (8, 8)': 1007, '(7, 0), (0, 0)': 1008, '(7, 0), (7, 1)': 1009, '(7, 0), (1, 0)': 1010, '(7, 0), (7, 2)': 1011, '(7, 0), (2, 0)': 1012, '(7, 0), (7, 3)': 1013, '(7, 0), (3, 0)': 1014, '(7, 0), (7, 4)': 1015, '(7, 0), (4, 0)': 1016, '(7, 0), (7, 5)': 1017, '(7, 0), (5, 0)': 1018, '(7, 0), (7, 6)': 1019, '(7, 0), (6, 0)': 1020, '(7, 0), (7, 7)': 1021, '(7, 0), (7, 8)': 1022, '(7, 0), (8, 0)': 1023, '(7, 1), (7, 0)': 1024, '(7, 1), (0, 1)': 1025, '(7, 1), (1, 1)': 1026, '(7, 1), (7, 2)': 1027, '(7, 1), (2, 1)': 1028, '(7, 1), (7, 3)': 1029, '(7, 1), (3, 1)': 1030, '(7, 1), (7, 4)': 1031, '(7, 1), (4, 1)': 1032, '(7, 1), (7, 5)': 1033, '(7, 1), (5, 1)': 1034, '(7, 1), (7, 6)': 1035, '(7, 1), (6, 1)': 1036, '(7, 1), (7, 7)': 1037, '(7, 1), (7, 8)': 1038, '(7, 1), (8, 1)': 1039, '(7, 2), (7, 0)': 1040, '(7, 2), (0, 2)': 1041, '(7, 2), (7, 1)': 1042, '(7, 2), (1, 2)': 1043, '(7, 2), (2, 2)': 1044, '(7, 2), (7, 3)': 1045, '(7, 2), (3, 2)': 1046, '(7, 2), (7, 4)': 1047, '(7, 2), (4, 2)': 1048, '(7, 2), (7, 5)': 1049, '(7, 2), (5, 2)': 1050, '(7, 2), (7, 6)': 1051, '(7, 2), (6, 2)': 1052, '(7, 2), (7, 7)': 1053, '(7, 2), (7, 8)': 1054, '(7, 2), (8, 2)': 1055, '(7, 3), (7, 0)': 1056, '(7, 3), (0, 3)': 1057, '(7, 3), (7, 1)': 1058, '(7, 3), (1, 3)': 1059, '(7, 3), (7, 2)': 1060, '(7, 3), (2, 3)': 1061, '(7, 3), (3, 3)': 1062, '(7, 3), (7, 4)': 1063, '(7, 3), (4, 3)': 1064, '(7, 3), (7, 5)': 1065, '(7, 3), (5, 3)': 1066, '(7, 3), (7, 6)': 1067, '(7, 3), (6, 3)': 1068, '(7, 3), (7, 7)': 1069, '(7, 3), (7, 8)': 1070, '(7, 3), (8, 3)': 1071, '(7, 4), (7, 0)': 1072, '(7, 4), (0, 4)': 1073, '(7, 4), (7, 1)': 1074, '(7, 4), (1, 4)': 1075, '(7, 4), (7, 2)': 1076, '(7, 4), (2, 4)': 1077, '(7, 4), (7, 3)': 1078, '(7, 4), (3, 4)': 1079, '(7, 4), (4, 4)': 1080, '(7, 4), (7, 5)': 1081, '(7, 4), (5, 4)': 1082, '(7, 4), (7, 6)': 1083, '(7, 4), (6, 4)': 1084, '(7, 4), (7, 7)': 1085, '(7, 4), (7, 8)': 1086, '(7, 4), (8, 4)': 1087, '(7, 5), (7, 0)': 1088, '(7, 5), (0, 5)': 1089, '(7, 5), (7, 1)': 1090, '(7, 5), (1, 5)': 1091, '(7, 5), (7, 2)': 1092, '(7, 5), (2, 5)': 1093, '(7, 5), (7, 3)': 1094, '(7, 5), (3, 5)': 1095, '(7, 5), (7, 4)': 1096, '(7, 5), (4, 5)': 1097, '(7, 5), (5, 5)': 1098, '(7, 5), (7, 6)': 1099, '(7, 5), (6, 5)': 1100, '(7, 5), (7, 7)': 1101, '(7, 5), (7, 8)': 1102, '(7, 5), (8, 5)': 1103, '(7, 6), (7, 0)': 1104, '(7, 6), (0, 6)': 1105, '(7, 6), (7, 1)': 1106, '(7, 6), (1, 6)': 1107, '(7, 6), (7, 2)': 1108, '(7, 6), (2, 6)': 1109, '(7, 6), (7, 3)': 1110, '(7, 6), (3, 6)': 1111, '(7, 6), (7, 4)': 1112, '(7, 6), (4, 6)': 1113, '(7, 6), (7, 5)': 1114, '(7, 6), (5, 6)': 1115, '(7, 6), (6, 6)': 1116, '(7, 6), (7, 7)': 1117, '(7, 6), (7, 8)': 1118, '(7, 6), (8, 6)': 1119, '(7, 7), (7, 0)': 1120, '(7, 7), (0, 7)': 1121, '(7, 7), (7, 1)': 1122, '(7, 7), (1, 7)': 1123, '(7, 7), (7, 2)': 1124, '(7, 7), (2, 7)': 1125, '(7, 7), (7, 3)': 1126, '(7, 7), (3, 7)': 1127, '(7, 7), (7, 4)': 1128, '(7, 7), (4, 7)': 1129, '(7, 7), (7, 5)': 1130, '(7, 7), (5, 7)': 1131, '(7, 7), (7, 6)': 1132, '(7, 7), (6, 7)': 1133, '(7, 7), (7, 8)': 1134, '(7, 7), (8, 7)': 1135, '(7, 8), (7, 0)': 1136, '(7, 8), (0, 8)': 1137, '(7, 8), (7, 1)': 1138, '(7, 8), (1, 8)': 1139, '(7, 8), (7, 2)': 1140, '(7, 8), (2, 8)': 1141, '(7, 8), (7, 3)': 1142, '(7, 8), (3, 8)': 1143, '(7, 8), (7, 4)': 1144, '(7, 8), (4, 8)': 1145, '(7, 8), (7, 5)': 1146, '(7, 8), (5, 8)': 1147, '(7, 8), (7, 6)': 1148, '(7, 8), (6, 8)': 1149, '(7, 8), (7, 7)': 1150, '(7, 8), (8, 8)': 1151, '(8, 0), (0, 0)': 1152, '(8, 0), (8, 1)': 1153, '(8, 0), (1, 0)': 1154, '(8, 0), (8, 2)': 1155, '(8, 0), (2, 0)': 1156, '(8, 0), (8, 3)': 1157, '(8, 0), (3, 0)': 1158, '(8, 0), (8, 4)': 1159, '(8, 0), (4, 0)': 1160, '(8, 0), (8, 5)': 1161, '(8, 0), (5, 0)': 1162, '(8, 0), (8, 6)': 1163, '(8, 0), (6, 0)': 1164, '(8, 0), (8, 7)': 1165, '(8, 0), (7, 0)': 1166, '(8, 0), (8, 8)': 1167, '(8, 1), (8, 0)': 1168, '(8, 1), (0, 1)': 1169, '(8, 1), (1, 1)': 1170, '(8, 1), (8, 2)': 1171, '(8, 1), (2, 1)': 1172, '(8, 1), (8, 3)': 1173, '(8, 1), (3, 1)': 1174, '(8, 1), (8, 4)': 1175, '(8, 1), (4, 1)': 1176, '(8, 1), (8, 5)': 1177, '(8, 1), (5, 1)': 1178, '(8, 1), (8, 6)': 1179, '(8, 1), (6, 1)': 1180, '(8, 1), (8, 7)': 1181, '(8, 1), (7, 1)': 1182, '(8, 1), (8, 8)': 1183, '(8, 2), (8, 0)': 1184, '(8, 2), (0, 2)': 1185, '(8, 2), (8, 1)': 1186, '(8, 2), (1, 2)': 1187, '(8, 2), (2, 2)': 1188, '(8, 2), (8, 3)': 1189, '(8, 2), (3, 2)': 1190, '(8, 2), (8, 4)': 1191, '(8, 2), (4, 2)': 1192, '(8, 2), (8, 5)': 1193, '(8, 2), (5, 2)': 1194, '(8, 2), (8, 6)': 1195, '(8, 2), (6, 2)': 1196, '(8, 2), (8, 7)': 1197, '(8, 2), (7, 2)': 1198, '(8, 2), (8, 8)': 1199, '(8, 3), (8, 0)': 1200, '(8, 3), (0, 3)': 1201, '(8, 3), (8, 1)': 1202, '(8, 3), (1, 3)': 1203, '(8, 3), (8, 2)': 1204, '(8, 3), (2, 3)': 1205, '(8, 3), (3, 3)': 1206, '(8, 3), (8, 4)': 1207, '(8, 3), (4, 3)': 1208, '(8, 3), (8, 5)': 1209, '(8, 3), (5, 3)': 1210, '(8, 3), (8, 6)': 1211, '(8, 3), (6, 3)': 1212, '(8, 3), (8, 7)': 1213, '(8, 3), (7, 3)': 1214, '(8, 3), (8, 8)': 1215, '(8, 4), (8, 0)': 1216, '(8, 4), (0, 4)': 1217, '(8, 4), (8, 1)': 1218, '(8, 4), (1, 4)': 1219, '(8, 4), (8, 2)': 1220, '(8, 4), (2, 4)': 1221, '(8, 4), (8, 3)': 1222, '(8, 4), (3, 4)': 1223, '(8, 4), (4, 4)': 1224, '(8, 4), (8, 5)': 1225, '(8, 4), (5, 4)': 1226, '(8, 4), (8, 6)': 1227, '(8, 4), (6, 4)': 1228, '(8, 4), (8, 7)': 1229, '(8, 4), (7, 4)': 1230, '(8, 4), (8, 8)': 1231, '(8, 5), (8, 0)': 1232, '(8, 5), (0, 5)': 1233, '(8, 5), (8, 1)': 1234, '(8, 5), (1, 5)': 1235, '(8, 5), (8, 2)': 1236, '(8, 5), (2, 5)': 1237, '(8, 5), (8, 3)': 1238, '(8, 5), (3, 5)': 1239, '(8, 5), (8, 4)': 1240, '(8, 5), (4, 5)': 1241, '(8, 5), (5, 5)': 1242, '(8, 5), (8, 6)': 1243, '(8, 5), (6, 5)': 1244, '(8, 5), (8, 7)': 1245, '(8, 5), (7, 5)': 1246, '(8, 5), (8, 8)': 1247, '(8, 6), (8, 0)': 1248, '(8, 6), (0, 6)': 1249, '(8, 6), (8, 1)': 1250, '(8, 6), (1, 6)': 1251, '(8, 6), (8, 2)': 1252, '(8, 6), (2, 6)': 1253, '(8, 6), (8, 3)': 1254, '(8, 6), (3, 6)': 1255, '(8, 6), (8, 4)': 1256, '(8, 6), (4, 6)': 1257, '(8, 6), (8, 5)': 1258, '(8, 6), (5, 6)': 1259, '(8, 6), (6, 6)': 1260, '(8, 6), (8, 7)': 1261, '(8, 6), (7, 6)': 1262, '(8, 6), (8, 8)': 1263, '(8, 7), (8, 0)': 1264, '(8, 7), (0, 7)': 1265, '(8, 7), (8, 1)': 1266, '(8, 7), (1, 7)': 1267, '(8, 7), (8, 2)': 1268, '(8, 7), (2, 7)': 1269, '(8, 7), (8, 3)': 1270, '(8, 7), (3, 7)': 1271, '(8, 7), (8, 4)': 1272, '(8, 7), (4, 7)': 1273, '(8, 7), (8, 5)': 1274, '(8, 7), (5, 7)': 1275, '(8, 7), (8, 6)': 1276, '(8, 7), (6, 7)': 1277, '(8, 7), (7, 7)': 1278, '(8, 7), (8, 8)': 1279, '(8, 8), (8, 0)': 1280, '(8, 8), (0, 8)': 1281, '(8, 8), (8, 1)': 1282, '(8, 8), (1, 8)': 1283, '(8, 8), (8, 2)': 1284, '(8, 8), (2, 8)': 1285, '(8, 8), (8, 3)': 1286, '(8, 8), (3, 8)': 1287, '(8, 8), (8, 4)': 1288, '(8, 8), (4, 8)': 1289, '(8, 8), (8, 5)': 1290, '(8, 8), (5, 8)': 1291, '(8, 8), (8, 6)': 1292, '(8, 8), (6, 8)': 1293, '(8, 8), (8, 7)': 1294, '(8, 8), (7, 8)': 1295}\n",
      "1296 unique moves\n"
     ]
    }
   ],
   "source": [
    "## FUNCTION TO GENERATE HASHABLE OUTPUT INDEX\n",
    "def generate_output_index():\n",
    "    \"\"\"\n",
    "    Creates an output index for all possible Tablut moves. Returns a dictionary: output_index['(0,0), (0,1)'] = 1\n",
    "    \"\"\"\n",
    "    output_index = {}\n",
    "    index_value = 0\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if k != j:\n",
    "                    output_index[f'({i}, {j}), ({i}, {k})'] = index_value\n",
    "                    index_value += 1\n",
    "                if k != i:\n",
    "                    output_index[f'({i}, {j}), ({k}, {j})'] = index_value\n",
    "                    index_value += 1\n",
    "    return output_index\n",
    "\n",
    "output_index = generate_output_index()\n",
    "print(output_index)\n",
    "print(f'{len(output_index)} unique moves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO DRAW BOARDSTATE AND TEST POSITIONS/TROUBLESHOOT\n",
    "def draw_board(board_state):\n",
    "    \"\"\"\n",
    "    Draw the game board using matplotlib based on the given board state.\n",
    "    \"\"\"\n",
    "    board_state = np.array(board_state)\n",
    "    board_state = np.reshape(board_state, (9, 9))\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(1, 9):\n",
    "        plt.axvline(x=i, color='black', linewidth=2)\n",
    "    for j in range(1, 9):\n",
    "        plt.axhline(y=j, color='black', linewidth=2)\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            piece = board_state[j][i]  # Note: matplotlib uses (x, y) which is (col, row) in numpy\n",
    "            if piece != 0:\n",
    "                if piece == 2:\n",
    "                    ax.text(i + 0.5, 8 - j + 0.5, 'B', color='black', ha='center', va='center', fontsize=20)\n",
    "                elif piece == 1:\n",
    "                    ax.text(i + 0.5, 8 - j + 0.5, 'W', color='red', ha='center', va='center', fontsize=20)\n",
    "                elif piece == 4:\n",
    "                    ax.text(i + 0.5, 8 - j + 0.5, 'C', color='green', ha='center', va='center', fontsize=20)\n",
    "                else:\n",
    "                    ax.text(i + 0.5, 8 - j + 0.5, 'K', color='orange', ha='center', va='center', fontsize=20)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(0, 9)\n",
    "    ax.set_ylim(0, 9)\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTION TO CREATE SOME OF THE CONSTANT EDGE VARIABLES AT INITIALISATION\n",
    "def generate_edges_set():\n",
    "    \"\"\"\n",
    "    Returns a set of all the board edge squares.\n",
    "    \"\"\"\n",
    "    edges = {(0, i) for i in range(9)} | {(8, i) for i in range(9)} | {(i, 0) for i in range(9)} | {(i, 8) for i in range(9)}\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BOARD CLASS RESPONSIBLE FOR PERFORMING BASIC GAMEPLAY\n",
    "class Board():\n",
    "    \"\"\"\n",
    "    Board object that encodes all information about current position\n",
    "    \"\"\"\n",
    "    # Basic piece constants\n",
    "    EMPTY = 0\n",
    "    WHITE = 1\n",
    "    BLACK = 2\n",
    "    KING = 3\n",
    "    EMPTY_CASTLE = 4\n",
    "\n",
    "    # Board specific constants\n",
    "    CASTLE = (4, 4)\n",
    "    CASTLE_SQUARES = {(3, 4), (4, 3), (4, 4), (4, 5), (5, 4)}\n",
    "\n",
    "    EDGES = generate_edges_set()\n",
    "\n",
    "    def __init__(self, zobrist):\n",
    "        # keep track of turn, board state, and legal moves cache\n",
    "        self.turn = self.WHITE\n",
    "        self.board = np.zeros((9, 9), dtype=int)\n",
    "        self.legal_moves = None\n",
    "        # Tracker for King restrictions\n",
    "        self.king_around_castle = False\n",
    "        self.king_position = False\n",
    "        # repetition counter will belong to the board, but its value be controlled by logic inside the game wrapper\n",
    "        self.repetition_counter = 0\n",
    "        self.no_legal_moves = False\n",
    "        # Position Hashing class and board state hash value\n",
    "        self.zobrist = zobrist\n",
    "        self.zobrist_hash = 0\n",
    "\n",
    "    def set_starting_position(self):\n",
    "        \"\"\"\n",
    "        Sets board state to Tablut starting position, sets King castle location flag.\n",
    "        \"\"\"\n",
    "        self.board = np.array([[self.EMPTY, self.EMPTY, self.EMPTY, self.BLACK, self.BLACK, self.BLACK, self.EMPTY, self.EMPTY, self.EMPTY],\n",
    "                            [self.EMPTY, self.EMPTY, self.EMPTY, self.EMPTY, self.BLACK, self.EMPTY, self.EMPTY, self.EMPTY, self.EMPTY],\n",
    "                            [self.EMPTY, self.EMPTY, self.EMPTY, self.EMPTY, self.WHITE, self.EMPTY, self.EMPTY, self.EMPTY, self.EMPTY],\n",
    "                            [self.BLACK, self.EMPTY, self.EMPTY, self.EMPTY, self.WHITE, self.EMPTY, self.EMPTY, self.EMPTY, self.BLACK],\n",
    "                            [self.BLACK, self.BLACK, self.WHITE, self.WHITE, self.KING, self.WHITE, self.WHITE, self.BLACK, self.BLACK],\n",
    "                            [self.BLACK, self.EMPTY, self.EMPTY, self.EMPTY, self.WHITE, self.EMPTY, self.EMPTY, self.EMPTY, self.BLACK],\n",
    "                            [self.EMPTY, self.EMPTY, self.EMPTY, self.EMPTY, self.WHITE, self.EMPTY, self.EMPTY, self.EMPTY, self.EMPTY],\n",
    "                            [self.EMPTY, self.EMPTY, self.EMPTY, self.EMPTY, self.BLACK, self.EMPTY, self.EMPTY, self.EMPTY, self.EMPTY],\n",
    "                            [self.EMPTY, self.EMPTY, self.EMPTY, self.BLACK, self.BLACK, self.BLACK, self.EMPTY, self.EMPTY, self.EMPTY]])\n",
    "\n",
    "        self.turn = self.WHITE\n",
    "        self.legal_moves = None\n",
    "        self.king_around_castle = True\n",
    "        self.king_position = (4,4)\n",
    "        self.repetition_counter = 0\n",
    "        self.no_legal_moves = False\n",
    "        self.zobrist_hash = self.zobrist.compute_hash(self.board)\n",
    "\n",
    "    def find_captures(self, to_square):\n",
    "        \"\"\"\n",
    "        Checks for any captures resulting from inputted move. Returns list of tuples (captured piece type, row, col).\n",
    "        \"\"\"\n",
    "        # list to hold any captures found as result of move\n",
    "        captures = []\n",
    "        # turn dependent variables to simplify capture checks\n",
    "        ally = {self.WHITE, self.KING, self.EMPTY_CASTLE} if self.turn == self.WHITE else {self.BLACK, self.EMPTY_CASTLE}\n",
    "        enemy = self.WHITE if self.turn == self.BLACK else self.BLACK\n",
    "\n",
    "        def add_captures(step):\n",
    "            \"\"\"\n",
    "            Helper to find captures in given direction. Appends relevant captures to captures list.\n",
    "            \"\"\"\n",
    "            enemy_index = (to_square[0] + step[0], to_square[1] + step[1])\n",
    "            ally_index = (to_square[0] + 2 * step[0], to_square[1] + 2 * step[1])\n",
    "            # check 'square two over' is on board\n",
    "            if not (0 <= ally_index[0] < 9 and 0 <= ally_index[1] < 9):\n",
    "                return\n",
    "            # if square two over is 'allied' in terms of capturing rights, check middle square.\n",
    "            if self.board[ally_index] in ally:\n",
    "                adjacent_piece = self.board[enemy_index]\n",
    "                if adjacent_piece == enemy:\n",
    "                    captures.append((adjacent_piece, enemy_index[0], enemy_index[1]))\n",
    "                # to handle King captures outside of the castle / castle borders\n",
    "                if adjacent_piece == self.KING and self.turn == self.BLACK and not self.king_around_castle:\n",
    "                    captures.append((adjacent_piece, enemy_index[0], enemy_index[1]))\n",
    "                    self.king_position = None\n",
    "\n",
    "        def add_king_captures(step):\n",
    "            \"\"\"\n",
    "            Helper to find King captures with modified conditions in / adjacent to castle. Appends relevant capture to captures list.\n",
    "            \"\"\"\n",
    "            non_attackers = {self.WHITE, self.EMPTY}\n",
    "            king_index = (to_square[0] + step[0], to_square[1] + step[1])\n",
    "            if king_index == self.king_position:\n",
    "                # look at squares adjacent to King, if any of these are White or Empty then it returns\n",
    "                for direction in [(-1, 0), (0, -1), (0, 1), (1, 0)]:\n",
    "                    neighbor_index = (king_index[0] + direction[0], king_index[1] + direction[1])\n",
    "                    if self.board[neighbor_index] in non_attackers:\n",
    "                        return False\n",
    "                # if function runs all the way through without returning, then the King is surrounded by capturing squares\n",
    "                captures.append((self.KING, king_index[0], king_index[1]))\n",
    "                self.king_position = None\n",
    "                return True\n",
    "\n",
    "        # iterate through adjacent squares, checking for captures\n",
    "        for direction in [(-1, 0), (0, -1), (0, 1), (1, 0)]:\n",
    "            add_captures(direction)\n",
    "\n",
    "        if self.turn == self.BLACK and self.king_around_castle:\n",
    "            for direction in [(-1, 0), (0, -1), (0, 1), (1, 0)]:\n",
    "                if add_king_captures(direction):\n",
    "                    break\n",
    "\n",
    "        return captures\n",
    "\n",
    "# TODO: implement ZH\n",
    "    def apply_move(self, move):\n",
    "        \"\"\"\n",
    "        Applies a move to the board. Takes a move as input and resets legal move 'cache'.\n",
    "        \"\"\"\n",
    "        from_square = move[0]\n",
    "        to_square = move[1]\n",
    "        piece_moved = self.board[from_square]\n",
    "\n",
    "        self.board[to_square] = piece_moved\n",
    "\n",
    "        # sets departed square Empty for all non-king pieces\n",
    "        if piece_moved != self.KING:\n",
    "            self.board[from_square] = self.EMPTY\n",
    "        else:\n",
    "            # set King's previous square as either empty or empty castle depending on whether it moved from castle\n",
    "            self.board[from_square] = self.EMPTY_CASTLE if self.king_position == self.CASTLE else self.EMPTY\n",
    "            # update King location markers\n",
    "            self.king_position = to_square\n",
    "            self.king_around_castle = True if to_square in self.CASTLE_SQUARES else False\n",
    "\n",
    "        # captures check\n",
    "        captures = self.find_captures(to_square)\n",
    "        for capture in captures:\n",
    "            self.board[(capture[1], capture[2])] = self.EMPTY\n",
    "\n",
    "        # switch to next player turn\n",
    "        self.turn = self.BLACK if self.turn == self.WHITE else self.WHITE\n",
    "        # reset legal move cache\n",
    "        self.legal_moves = None\n",
    "\n",
    "        # generate Zobrist for new boardstate\n",
    "        self.zobrist_hash = self.zobrist.update_hash(hash_value=self.zobrist_hash, piece=piece_moved,\n",
    "                                                         from_pos=from_square, to_pos=to_square, captures=captures)\n",
    "        # query cache with new hash, update repetition count. Alternatively could do this in is_terminal and remove repetition counter. How do I include the node ids for MCTS though?\n",
    "        # I think this should be done in the game wrapper. Almost tempted to remove all the zobrist hashing references.\n",
    "\n",
    "\n",
    "    def generate_moves(self):\n",
    "        \"\"\"\n",
    "        Collates and returns all legal moves for the given board state.\n",
    "        \"\"\"\n",
    "        if self.legal_moves is None:\n",
    "            moves = []\n",
    "\n",
    "            for row in range(9):\n",
    "                for col in range(9):\n",
    "                    if self.board[row, col] == self.turn:\n",
    "                        for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                            r, c = row + dr, col + dc\n",
    "                            while 0 <= r < 9 and 0 <= c < 9:\n",
    "                                target_square = self.board[r, c]\n",
    "                                if target_square == self.WHITE or target_square == self.BLACK or target_square == self.KING:\n",
    "                                    break\n",
    "                                if target_square != self.EMPTY_CASTLE:\n",
    "                                    moves.append(((row, col), (r, c)))\n",
    "                                r += dr\n",
    "                                c += dc\n",
    "                    elif self.turn == self.WHITE and (row, col) == self.king_position:\n",
    "                        for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                            r, c = row + dr, col + dc\n",
    "                            while 0 <= r < 9 and 0 <= c < 9:\n",
    "                                target_square = self.board[r, c]\n",
    "                                if target_square == self.WHITE or target_square == self.BLACK:\n",
    "                                    break\n",
    "                                moves.append(((row, col), (r, c)))\n",
    "                                r += dr\n",
    "                                c += dc\n",
    "            self.legal_moves = moves\n",
    "            self.no_legal_moves = False if moves else True\n",
    "        return self.legal_moves\n",
    "\n",
    "    # TODO this is clearly not ideal - expensive process. Could implement some kind of speed-ups?\n",
    "    def is_surround(self):\n",
    "        \"\"\"\n",
    "        Determines if white pieces are surrounded to meet conditions for Black win.\n",
    "        Returns True if surrounded, False otherwise.\n",
    "        \"\"\"\n",
    "        # add searched coords to a set to reference\n",
    "        searched_squares = set()\n",
    "\n",
    "        def flood_fill(coords):\n",
    "            \"\"\"\n",
    "            Recursive DFS flood fill function to determine if the white pieces are surrounded.\n",
    "            True if flood fill finds a white piece / king, else false.\n",
    "            \"\"\"\n",
    "            row, col = coords\n",
    "            if 0 <= row < 9 and 0 <= col < 9 and (row, col) not in searched_squares:\n",
    "                searched_squares.add((row, col))\n",
    "                if self.board[row][col] == self.WHITE or self.board[row][col] == self.KING:\n",
    "                    return True\n",
    "                elif self.board[row][col] == self.EMPTY:\n",
    "                    for dr, dc in [(1, 0), (-1, 0), (0, 1), (0, -1)]:\n",
    "                        if flood_fill((row + dr, col + dc)):\n",
    "                            return True\n",
    "                return False\n",
    "\n",
    "        # Check for surround condition from each edge square\n",
    "        for edge in self.EDGES:\n",
    "            if self.board[edge] == self.WHITE or self.board[edge] == self.KING:\n",
    "                return False\n",
    "            elif edge not in searched_squares and self.board[edge] != self.BLACK:\n",
    "                if flood_fill(edge):\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def is_terminal(self):\n",
    "        \"\"\"\n",
    "        Detects terminal position, returns tuple (bool, int)\n",
    "        \"\"\"\n",
    "        winner = None\n",
    "        # white wins if King reaches edge or black has no moves\n",
    "        if self.turn == self.BLACK: # terminal check occurs at beginning of each player's turn (each player can only win on the other's turn)\n",
    "            if self.king_position in self.EDGES or self.no_legal_moves:\n",
    "                winner = self.WHITE\n",
    "                return True, winner\n",
    "        # black wins by capture, or game repetition, or no moves, or surrounding.\n",
    "        else:\n",
    "            if self.king_position is None or self.repetition_counter == 3 or self.no_legal_moves or self.is_surround():\n",
    "                winner = self.BLACK\n",
    "                return True, winner\n",
    "\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We might need to tinker with this as we find bugs, but it has passed every basic case that I've set up manually, and the random games are finishing in a reasonable number of moves / with correct endgame positions. Let's continue onto the hashing problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zobrist Hashing\n",
    "The first question is do I need to do this? I've already asked this above. Necessarily, no. But I want to avoid the issue of repetitions. However, does this mean that I will be generating thousands of keys for all the board states reached in a game? Assume a game takes 50 moves. Performing 100 iterations of MCTS every move, that means 5,000 dictionary entries. It's not ideal. But these will not all be stored at once. I'll iteratively create dictionaries for new MCTS searches, which means that only a max of 100 + moves played + 1. But they will all need to be hashed and queried x5000, and that's not nothing. \n",
    "\n",
    "It seems like the best way to hash boardstates for these types of games is [Zobrist Hashing](https://en.wikipedia.org/wiki/Zobrist_hashing#:~:text=Zobrist%20hashing%20is%20the%20first%20known%20instance%20of%20tabulation%20hashing,are%20either%20black%20or%20white.). With Zobrist Hashing, we should be able to incrementally update the hash with XOR operations, and avoid the expensive process of recalculating it from board position. I think that the main process of tracking the hash will be inside the Board object, so we will pass our ZobristHashing class in at Board instantiation. Also, we will adapt the apply_move method to update the stored hash value. To do this, we'll also need to know which pieces are captured so I can XOR out during the increment (this will require a quick refactor of what find_captures returns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZobristHashing:\n",
    "    def __init__(self):\n",
    "        self.board_size = 9\n",
    "        self.pieces = [1, 2, 3, 4]\n",
    "        self.zobrist_table = {}       # Dictionary to store the random values for hashing\n",
    "        self.init_zobrist_table()\n",
    "\n",
    "    def init_zobrist_table(self):\n",
    "        \"\"\"Generate random 64-bit integers for each piece-position triple\"\"\"\n",
    "        for piece in self.pieces:\n",
    "            for row in range(self.board_size):\n",
    "                for col in range(self.board_size):\n",
    "                    self.zobrist_table[(piece, row, col)] = random.getrandbits(64)\n",
    "\n",
    "    def compute_hash(self, board):\n",
    "        \"\"\"Returns hash from inputted board state\"\"\"\n",
    "        hash_value = 0  # Initialize the hash value to 0\n",
    "        for row in range(self.board_size):\n",
    "            for col in range(self.board_size):\n",
    "                piece = board[row][col]  # Get the piece at the current position\n",
    "                if piece != 0:\n",
    "                    # XOR the hash value with the Zobrist value for the piece at this position\n",
    "                    hash_value ^= self.zobrist_table[(piece, row, col)]\n",
    "        return hash_value  # Return the final hash value\n",
    "\n",
    "    def update_hash(self, hash_value, piece, from_pos, to_pos, captures):\n",
    "        \"\"\"Returns incrementally updated hash value given old hash, piece moved, from square, to square, and list of captures (piece, row, col)\"\"\"\n",
    "        # XOR the hash value with the Zobrist value for the piece's old position\n",
    "        hash_value ^= self.zobrist_table[(piece, from_pos[0], from_pos[1])]\n",
    "        # XOR in the Empty castle if necessary\n",
    "        if from_pos == (4, 4):\n",
    "            hash_value ^= self.zobrist_table[(4, 4, 4)]\n",
    "        # XOR the hash value with the Zobrist value for the piece's new position\n",
    "        hash_value ^= self.zobrist_table[(piece, to_pos[0], to_pos[1])]\n",
    "        # XOR out the empty castle if need be\n",
    "        if to_pos == (4, 4):\n",
    "            hash_value ^= self.zobrist_table[(4, 4, 4)]\n",
    "        # deal with captures if there are any - captures is list of [(piece, row, col)]\n",
    "        if captures:\n",
    "            for capture in captures:\n",
    "                hash_value ^= self.zobrist_table[capture]\n",
    "\n",
    "        return hash_value  # Return the updated hash value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white won in 89 moves!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = ZobristHashing()\n",
    "b = Board(zobrist=z)\n",
    "b.set_starting_position()\n",
    "\n",
    "game_log = []\n",
    "while b.is_terminal()[0] == False:\n",
    "    move = random.choice(b.generate_moves())\n",
    "    b.apply_move(move)\n",
    "    game_log.append(deepcopy(b.board))\n",
    "\n",
    "winner = 'white' if b.is_terminal()[1] == 1 else 'black'\n",
    "print(f'{winner} won in {len(game_log)} moves!')\n",
    "\n",
    "draw_board(game_log[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7798751345182605901\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = Board(zobrist=z)\n",
    "print(b.zobrist_hash)\n",
    "b.set_starting_position()\n",
    "print(b.zobrist_hash)\n",
    "draw_board(b.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11145809676279413079\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.apply_move(((0,3), (0,2)))\n",
    "print(b.zobrist_hash)\n",
    "draw_board(b.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's quickly test that, in a randomly simulated game, the updated hash is always equal to the computed hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same hashes for a game of 107 moves.\n"
     ]
    }
   ],
   "source": [
    "zobrist = ZobristHashing()\n",
    "b = Board(zobrist)\n",
    "b.set_starting_position()\n",
    "success = True\n",
    "counter = 0\n",
    "moves = []\n",
    "boards = []\n",
    "incremented_hashes = []\n",
    "computed_hashes = []\n",
    "while b.is_terminal()[0] == False:\n",
    "    computed_hash = zobrist.compute_hash(b.board)\n",
    "    computed_hashes.append(computed_hash)\n",
    "    incremented_hash = b.zobrist_hash\n",
    "    incremented_hashes.append(incremented_hash)\n",
    "    if computed_hash != incremented_hash:\n",
    "        print(f'hashes are not equal on move {counter}')\n",
    "        success = False\n",
    "        break\n",
    "    move = random.choice(b.generate_moves())\n",
    "    moves.append(move)\n",
    "    b.apply_move(move)\n",
    "    boards.append(deepcopy(b.board))\n",
    "    counter += 1\n",
    "\n",
    "if success:\n",
    "    print(f\"Same hashes for a game of {counter} moves.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! I've tested this >100 times now and, after some troubleshooting with the game/hashing mechanics, everything seems to work. We have the main building blocks of gameplay, but before we start putting everything together, let's start solidifying our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "------\n",
    "While my opposed to my proof of concept iteration was entirely fully connected,Dense layers, I want to experiment with using CNNs here. I'm trying to closely follow [Leela's model architecture](https://lczero.org/dev/backend/nn/#fn:3), using a core residual tower with successive Squeeze and Excitation Layers. I've attached a model diagram showing the topology in more detail. There are two ouputs, the 'Policy Head', which outputs a probability distribution mapped to all possible moves, and the 'Value Head', which outputs an assessment of the positional score. Because a tanh activation function is applied, this score will be between -1 and 1, the closer to 1 the more confident that this is a winning posiiton for the player whose turn it is. This is the first time that I've tried to construct a model of this complexity.\n",
    "\n",
    "__A note on policy output:__\n",
    "\n",
    "In my proof of concept model inspired by Klein's Hexapawn implementation, I used a flat distribution of all legal moves as my output. In that model, which was only comprised of fully connected layers, the tensor was then flattened and again fully connected to an output vector of the same size as the vector containing all possible moves. A softmax activation function was applied during the output layer. The index of the output vector corresponded to the index value of a valid move tuple, and the output value at every index represented the probability of the corresponding move being best. Of course, some moves are not legal in the input position, so these are masked out on return.\n",
    "\n",
    "It seems that AlphaZero and Leela both looked at this approach, but went with a different direction. Moves were considered as possible moves from a square (piece independent). this is represented as 8 x 8 x 73 (8 x 8 for start squares on a chess board and 73 representing: 1. the 8 x 7 Queen moves of 'direction moved' x 'squares moved'; 2. the 8 Knight moves; 3. the 3 x 3 of 'pawn promotion move directions' x 'pawn underpromotions'. Initially, I wondered why they didn't encode this simply from every start square, with every possible legal move from that square, but the representation space ends up being significantly larger. In Leela, at least, the Policy Head convolves the tensor down in size to a tensor shape matching the 73x8x8 shape (actually 80x8x8 including zero-padding), and then flattens and maps the output vector to a flattened representation of the possible moves space (impossible moves are given the value of -1). The values of the legal moves in this moves space are themselves mapped to the indices of the flat legal moves vector containing moves recorded in a format that can be interpreted by the gameplay engine. I've included an example of what my output space looks like to help build an intuition here. AlphaZero mentioned in their paper that both approaches to output work, but that the multi-dimensional output space approach converges faster. It's my intuition that this approach avoids some potential information bottlenecks, and is a smoother transition for the model to learn from.\n",
    "\n",
    "I had to spend a while researching the mapping process Leela uses, and the padding structure. The code for the mapping layer and a very helpful description can be found [here](https://github.com/LeelaChessZero/lc0/blob/master/src/neural/cuda/layers.cc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296 legal moves indexed.\n",
      "--------------------------------------------------\n",
      "Example - Plane 1 of 32 Representing all '1 Move Left' Moves. Note that all impossible moves (in this case, moving a piece on the leftmost column) are indexed -1.\n",
      " -------------------------------------------------- \n",
      " [[  -1   16   32   48   64   80   96  112  128]\n",
      " [  -1  160  176  192  208  224  240  256  272]\n",
      " [  -1  304  320  336  352  368  384  400  416]\n",
      " [  -1  448  464  480  496  512  528  544  560]\n",
      " [  -1  592  608  624  640  656  672  688  704]\n",
      " [  -1  736  752  768  784  800  816  832  848]\n",
      " [  -1  880  896  912  928  944  960  976  992]\n",
      " [  -1 1024 1040 1056 1072 1088 1104 1120 1136]\n",
      " [  -1 1168 1184 1200 1216 1232 1248 1264 1280]]\n",
      "--------------------------------------------------\n",
      "For example, the key '16' returns the move tuple ((from row, from col), (to row, to col)): ((0, 1), (0, 0)).\n"
     ]
    }
   ],
   "source": [
    "# CREATING POLICY OUTPUT MAP AND MOVE INDEX\n",
    "def build_policy_map():\n",
    "    # initialise space of the right size full of -1\n",
    "    policy_map = np.full((32, 9, 9), -1)\n",
    "    index_to_move = {}\n",
    "    # to iterate and assign move indexes\n",
    "    index = 0\n",
    "    for row in range(9):\n",
    "        for col in range(9):\n",
    "            for left_moves in range(0, 8):\n",
    "                if col > left_moves:\n",
    "                    policy_map[(left_moves, row, col)] = index\n",
    "                    index_to_move[index] = ((row, col), (row, col - left_moves - 1))\n",
    "                    index += 1\n",
    "\n",
    "            for right_moves in range(0, 8):\n",
    "                if col < 8 - right_moves:\n",
    "                    policy_map[(8 + right_moves, row, col)] = index\n",
    "                    index_to_move[index] = ((row, col), (row, col + right_moves + 1))\n",
    "                    index += 1\n",
    "\n",
    "            for up_moves in range(0, 8):\n",
    "                if row > up_moves:\n",
    "                    policy_map[(16 + up_moves, row, col)] = index\n",
    "                    index_to_move[index] = ((row, col), (row - up_moves - 1, col))\n",
    "                    index += 1\n",
    "\n",
    "            for down_moves in range(0, 8):\n",
    "                if row < 8 - down_moves:\n",
    "                    policy_map[(24 + down_moves, row, col)] = index\n",
    "                    index_to_move[index] = ((row, col), (row + down_moves + 1, col))\n",
    "                    index += 1\n",
    "\n",
    "    move_to_index = {move: idx for idx, move in index_to_move.items()}\n",
    "\n",
    "    return policy_map.flatten(), index_to_move, move_to_index\n",
    "\n",
    "policy_map, index_to_move, move_to_index = build_policy_map()\n",
    "\n",
    "print(f'{policy_map.max()+1} legal moves indexed.')\n",
    "print('-'*50)\n",
    "print(\"Example - Plane 1 of 32 Representing all '1 Move Left' Moves. Note that all impossible moves (in this case, moving a piece on the leftmost column) are indexed -1.\\n\",'-'*50,'\\n', policy_map.reshape((32, 9, 9))[0])\n",
    "print('-'*50)\n",
    "print(f\"For example, the key '16' returns the move tuple ((from row, from col), (to row, to col)): {index_to_move[16]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at tensor[(0, 4, 4)] should correspond to move index 640.\n",
      "Move index 640 corresponds to move input ((0, 2), (1, 2)).\n",
      "Policy vector length 2916 created, where the index of every value corresponds to a unique move index. At index 640, corresponding value is 0.5, mapped correctly from its original place in tensor[(0,4,4)]\n"
     ]
    }
   ],
   "source": [
    "# MODEL THE MAPPING FROM 73x8x8 OUTPUT TENSOR TO PROBABILITY VECTOR\n",
    "mapping_indices = np.zeros(1296, dtype='int16') # creates new vector length 1296 where index = move_index, value = tensor_index for all possible moves\n",
    "for index, value in enumerate(policy_map):\n",
    "    if value != -1:\n",
    "        mapping_indices[value] = index\n",
    "\n",
    "import tensorflow as tf\n",
    "# imagine this tensor is the output. I've set the value at (0, 4, 4), or index 40 when flattened, to 0.5 to make sure values are mapped correctly\n",
    "tensor = np.full((36,9,9), 0.1)\n",
    "tensor[(0, 4, 4)] = 0.5\n",
    "tensor = tf.constant(tensor)\n",
    "print(f'Value at tensor[(0, 4, 4)] should correspond to move index {policy_map[40]}.')\n",
    "print(f'Move index {policy_map[40]} corresponds to move input {index_to_move[40]}.')\n",
    "\n",
    "tensor = tf.reshape(tensor, [-1]) # flattening the tensor\n",
    "\n",
    "output = tf.gather(tensor, mapping_indices) # maps every value to the corresponding move index in a vector of all possible moves.\n",
    "print(f'Policy vector length {len(tensor)} created, where the index of every value corresponds to a unique move index. At index 640, corresponding value is {output[640]}, mapped correctly from its original place in tensor[(0,4,4)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "       0.1, 0.1, 0.1, 0.5, 0.1, 0.1, 0.1], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Layer, ReLU, Add, Dense, Flatten, Input, GlobalAveragePooling2D, Multiply, Reshape, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "tensor = np.full((3,36,9,9), 0.1)\n",
    "tensor[(1, 0, 0, 1)] = 0.5\n",
    "tensor = tf.constant(tensor)\n",
    "\n",
    "tensor = Flatten()(tensor)\n",
    "indices = tf.tile(tf.expand_dims(mapping_indices, 0), [tf.shape(tensor)[0], 1])\n",
    "\n",
    "output = tf.gather(tensor, indices, batch_dims=1)\n",
    "output[1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">28,288</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalization  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span>  re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " squeeze_excitation  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitation</span>)                                                   \n",
       "\n",
       " add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  squeeze_excitati \n",
       "                                                     re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span>  re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">20,772</span>  re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2592</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  re_lu_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2916</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "\n",
       " dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">331,904</span>  flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "\n",
       " policy_head          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1296</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PolicyMap</span>)                                                           \n",
       "\n",
       " value_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>  dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m49\u001b[0m)            \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m28,288\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalization  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu (\u001b[38;5;33mReLU\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_1 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_3 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_5 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_7 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_9 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_11 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_13 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_15 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_17 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,864\u001b[0m  re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " squeeze_excitation  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m3,216\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mSqueezeExcitation\u001b[0m)                                                   \n",
       "\n",
       " add_19 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  squeeze_excitati \n",
       "                                                     re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " re_lu_20 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m36,928\u001b[0m  re_lu_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m32\u001b[0m)        \u001b[38;5;34m2,048\u001b[0m  re_lu_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m256\u001b[0m  conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m32\u001b[0m)          \u001b[38;5;34m128\u001b[0m  conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " re_lu_21 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " re_lu_22 (\u001b[38;5;33mReLU\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m32\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m36\u001b[0m)       \u001b[38;5;34m20,772\u001b[0m  re_lu_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2592\u001b[0m)                \u001b[38;5;34m0\u001b[0m  re_lu_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2916\u001b[0m)                \u001b[38;5;34m0\u001b[0m  conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "\n",
       " dense_20 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m331,904\u001b[0m  flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "\n",
       " policy_head          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1296\u001b[0m)                \u001b[38;5;34m0\u001b[0m  flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mPolicyMap\u001b[0m)                                                           \n",
       "\n",
       " value_head (\u001b[38;5;33mDense\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 \u001b[38;5;34m129\u001b[0m  dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,195,269</span> (4.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,195,269\u001b[0m (4.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,192,389</span> (4.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,192,389\u001b[0m (4.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,880\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "# Clear all previously registered custom objects\n",
    "keras.saving.get_custom_objects().clear()\n",
    "\n",
    "@keras.saving.register_keras_serializable(package=\"SELayer\")\n",
    "class SqueezeExcitation(Layer):\n",
    "    def __init__(self, filters, se_ratio, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.se_ratio = se_ratio\n",
    "        self.dense1 = Dense(filters // se_ratio, activation='relu')\n",
    "        self.dense2 = Dense(2 * filters)\n",
    "        self.reshape = Reshape([1, 1, filters * 2])\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(SqueezeExcitation, self).build(input_shape)\n",
    "\n",
    "    def call(self, input_x):\n",
    "        squeeze = GlobalAveragePooling2D()(input_x)\n",
    "\n",
    "        excitation = self.dense1(squeeze)\n",
    "        excitation = self.dense2(excitation)\n",
    "        excitation = self.reshape(excitation)\n",
    "        scale, bias = tf.split(excitation, num_or_size_splits=2, axis=-1)\n",
    "        scale = Activation('sigmoid')(scale)\n",
    "        output = Multiply()([input_x, scale])\n",
    "        output = Add()([output, bias])\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"se_ratio\": self.se_ratio\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        filters = config.pop(\"filters\")\n",
    "        se_ratio = config.pop(\"se_ratio\")\n",
    "        return cls(filters, se_ratio, **config)\n",
    "\n",
    "@keras.saving.register_keras_serializable(package=\"PolicyMap\")\n",
    "class PolicyMap(tf.keras.layers.Layer):\n",
    "    def __init__(self, mapping_indices, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mapping_indices = tf.constant(mapping_indices, dtype=tf.int32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        indices = tf.tile(tf.expand_dims(self.mapping_indices, 0), [batch_size, 1])\n",
    "        return tf.gather(inputs, indices, batch_dims=1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PolicyMap, self).get_config()\n",
    "        config.update({'mapping_indices': self.mapping_indices.numpy().tolist()})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        mapping_indices = config.pop('mapping_indices')\n",
    "        return cls(mapping_indices, **config)\n",
    "\n",
    "def residual_block(x, filters, se_ratio):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SqueezeExcitation(filters, se_ratio)(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def policy_branch(x, filters, policy_conv_size):\n",
    "    # one conv2d, batch normalization, relu sequence\n",
    "    policy = Conv2D(filters, kernel_size=3, padding='same', use_bias=True)(x)\n",
    "    policy = BatchNormalization()(policy)\n",
    "    policy = ReLU()(policy)\n",
    "    # one convolution down to map size + padding\n",
    "    policy = Conv2D(policy_conv_size, kernel_size=3, padding='same', use_bias = True)(policy)\n",
    "    # flatten and map\n",
    "    policy = Flatten()(policy)\n",
    "\n",
    "    return policy\n",
    "\n",
    "def value_branch(x, value_conv_size):\n",
    "    # note I am following AlphaZero/classical Leela approach here as there are no draws.\n",
    "    # one conv2D down in size, batch normalization, relu sequence\n",
    "    value = Conv2D(value_conv_size, kernel_size=1, padding='same', use_bias=False)(x)\n",
    "    value = BatchNormalization()(value)\n",
    "    value = ReLU()(value)\n",
    "    # flatten and fully connected layer with relu\n",
    "    value = Flatten()(value)\n",
    "    value = Dense(128, activation='relu')(value)\n",
    "\n",
    "    return value\n",
    "\n",
    "def create_model(input_shape, mapping_indices, filters=64, num_residual_blocks=10, se_ratio=4, policy_conv_size=36, value_conv_size=32):\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    # Initial Input Convolutional Layer\n",
    "    x = Conv2D(filters, kernel_size=3, padding='same', use_bias=True)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Residual Blocks\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = residual_block(x, filters, se_ratio)\n",
    "\n",
    "    # Policy head\n",
    "    policy = policy_branch(x, filters, policy_conv_size)\n",
    "    policy_output = PolicyMap(mapping_indices, name='policy_head', trainable=False)(policy)\n",
    "\n",
    "    # Value head\n",
    "    value = value_branch(x, value_conv_size)\n",
    "    value_output = Dense(1, activation='tanh', name='value_head')(value)\n",
    "\n",
    "    model = Model(inp, [policy_output, value_output])\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_shape = (9, 9, 49)  # Adjust the shape as needed\n",
    "\n",
    "model = create_model(input_shape, mapping_indices)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my loss function I am following the AlphaZero paper and using the sum of:\n",
    "1. Mean-squared error for value head\n",
    "2. Cross-entropy loss for policy head\n",
    "\n",
    "[Cross-entropy loss](https://en.wikipedia.org/wiki/Cross-entropy) is a very interesting concept, and I'll probe this area slightly longer to visualize what our loss function is telling us, exactly. Dealing with type of loss means dipping our toes into information theory. We treat the policy head output of our model as unnormalised log probabilities (logits), and apply a softmax activation function to produce normalized probabilities. These are then compared with the observed probability distribution to calculate our loss. The cross-entropy loss is defined as:\n",
    "\n",
    "$$\n",
    "H(y, p) = -\\sum_{i} y_i \\log(p_i)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $y_i$ is the true probability of class $i$ (in this case, whether the move was selected or not).\n",
    "- $p_i$ is the predicted probability of class $i$ (the output of the softmax function, the model prediction of the probability that a move was selected).\n",
    "- $i$ indexes over all of our classes (possible moves).\n",
    "\n",
    "When we have fleshed out our Reinforcement Learning pipeline, our policy target will be informed by node visit count (or PUCT score, or another metric tbd) during Monte-Carlo Tree Search. We can convert this to probability, in a way that can then be learned and generalized on (in theory!) by the model. We'll aim to minimize the KL Divergence between these two distributions (as our entropy, the right hand term of categorical cross entropy, is a fixed constant in this case). Better explanation in [this link](https://stats.stackexchange.com/questions/357963/what-is-the-difference-between-cross-entropy-and-kl-divergence).\n",
    "\n",
    "An issue with applying softmax to this probability distribution (given its size, and the small proportion of moves that will be legal at one time) is the nature of squashing it between 0 and 1. During my test build, where I used a simple categorical cross-entropy on one hot encoded move played, I ran into issues when no legal move had large enough log odds to be recognised as >0 after softmax was applied. Because of this, let's implement a custom loss function that masks out illegal moves by manually changing their logit value to a large negative number, ensuring that they will be set to zero once softmax is applied. The model will learn to avoid illegal moves and I won't run into any teething problems while the model is bad at recognising them organically (I believe that Alphazero did not mask out illegal moves in their policy target, but I'm trying to be as lean as possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM POLICY LOSS FUNCTION\n",
    "@keras.saving.register_keras_serializable()\n",
    "def policy_loss(target, output):\n",
    "    # apply the illegal move mask\n",
    "\n",
    "    def mask_policy(target, output):\n",
    "        output = tf.cast(output, tf.float32)\n",
    "\n",
    "        # mask illegal moves\n",
    "        move_is_legal = tf.greater_equal(target, 0)\n",
    "\n",
    "        # Replace logits of illegal moves with a large negative value\n",
    "        illegal_filler = tf.zeros_like(output) - 1.0e5\n",
    "        output = tf.where(move_is_legal, output, illegal_filler)\n",
    "\n",
    "        # turn all -1 values in target to 0\n",
    "        target = tf.nn.relu(target)\n",
    "\n",
    "        return target, output\n",
    "\n",
    "    target, output = mask_policy(target, output)\n",
    "\n",
    "    # Compute cross-entropy loss\n",
    "    policy_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.stop_gradient(target), logits=output\n",
    "    )\n",
    "\n",
    "    # Return the mean cross-entropy loss across batch\n",
    "    return tf.reduce_mean(policy_cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my optimizer, I'll be using [SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) with [Nesterov Momentum](https://stats.stackexchange.com/questions/179915/whats-the-difference-between-momentum-based-gradient-descent-and-nesterovs-acc). This seems state of the art for this application, even if it is relatively old compared to other trendier optimizers. Apparently Adam can prove unreliable under prolonged RL training - no doubt it would be a great option for a SL approach as it seems to smash image recognition tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_nesterov = tf.keras.optimizers.SGD(learning_rate=0.2, nesterov=True)\n",
    "\n",
    "model.compile(optimizer = sgd_nesterov, loss={'value_head' : 'mean_squared_error', 'policy_head' : policy_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
      "------------------\n",
      "Policy output: [[ -201.7803   -1962.8569    -271.49545  ...    -6.368086  3138.9854\n",
      "    -26.123873]]\n",
      "Value output: [[1.]]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a numpy array of shape (1, 49, 9, 9) with random values of either 0 or 1\n",
    "sample_input = np.random.randint(2, size=(1, 49, 9, 9))\n",
    "\n",
    "sample_input = sample_input.astype(np.float32)\n",
    "\n",
    "# Transpose to put channels last\n",
    "sample_input = np.transpose(sample_input, (0, 2, 3, 1))\n",
    "\n",
    "# Generate predictions using the randomly initialised model\n",
    "policy_output, value_output = model.predict(sample_input)\n",
    "\n",
    "print(\"------------------\")\n",
    "print(\"Policy output:\", policy_output)\n",
    "print(\"Value output:\", value_output)\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. The performance of the model, even its ability to train, is still tbd, but this is no small milestone - we are getting the policy and value output in a format that at least looks right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "To test that we are able to train the model, and because I've already created a pipeline for supervised training, let's reuse the game data that we've scraped from Aage Nielsen's site and try to train a model. Using a rudimentary model and a barebones input I already saw that we could outperform a random agent in the proof of concept work (hardly a brag!). This will also perform the important work of validating that the game logic is correct by validating it with actual gameplay.\n",
    "\n",
    "Steps will be:\n",
    "\n",
    "1. Load training data\n",
    "2. Iterate through moves. I might as well try to use a generalizable gameplay wrapper, where the moves are inputted to the engine in sequence and the tensors are constructed around this. There will be issues with terminal checks, as most of the games (annoyingly) are settled by resignation - not sure this is in keeping with the Viking ethos, but I'll leave it there.\n",
    "3. build and store tensor for each move, and store associated policy (move index) and value (W/L) target data\n",
    "4. create logic for data augmentation - this will be reused later to greatly increase the impact of our MCTS data generation\n",
    "5. batch train our model\n",
    "6. test performance on a random agent (and perhaps on the proof of concept model if I feel like facilitating this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>White_Player</th>\n",
       "      <th>Black_Player</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Win_Type</th>\n",
       "      <th>Move</th>\n",
       "      <th>spil</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Move_Number</th>\n",
       "      <th>First_Player</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hagbard</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>White</td>\n",
       "      <td>full</td>\n",
       "      <td>c5-c8</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white_starts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hagbard</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>White</td>\n",
       "      <td>full</td>\n",
       "      <td>b5-c5</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>white_starts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hagbard</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>White</td>\n",
       "      <td>full</td>\n",
       "      <td>e7-a7</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>white_starts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  White_Player Black_Player Winner Win_Type   Move  spil  Game_ID  \\\n",
       "0      Hagbard       Thomas  White     full  c5-c8    49        0   \n",
       "1      Hagbard       Thomas  White     full  b5-c5    49        0   \n",
       "2      Hagbard       Thomas  White     full  e7-a7    49        0   \n",
       "\n",
       "   Move_Number  First_Player  \n",
       "0            0  white_starts  \n",
       "1            1  white_starts  \n",
       "2            2  white_starts  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. LOAD DATA\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../../data/tablut_games_clean.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>White_Player</th>\n",
       "      <th>Black_Player</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Win_Type</th>\n",
       "      <th>Move</th>\n",
       "      <th>spil</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Move_Number</th>\n",
       "      <th>First_Player</th>\n",
       "      <th>Move_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hagbard</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>White</td>\n",
       "      <td>full</td>\n",
       "      <td>c5-c8</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white_starts</td>\n",
       "      <td>((4, 2), (7, 2))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hagbard</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>White</td>\n",
       "      <td>full</td>\n",
       "      <td>b5-c5</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>white_starts</td>\n",
       "      <td>((4, 1), (4, 2))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hagbard</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>White</td>\n",
       "      <td>full</td>\n",
       "      <td>e7-a7</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>white_starts</td>\n",
       "      <td>((6, 4), (6, 0))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  White_Player Black_Player Winner Win_Type   Move  spil  Game_ID  \\\n",
       "0      Hagbard       Thomas  White     full  c5-c8    49        0   \n",
       "1      Hagbard       Thomas  White     full  b5-c5    49        0   \n",
       "2      Hagbard       Thomas  White     full  e7-a7    49        0   \n",
       "\n",
       "   Move_Number  First_Player      Move_Encoded  \n",
       "0            0  white_starts  ((4, 2), (7, 2))  \n",
       "1            1  white_starts  ((4, 1), (4, 2))  \n",
       "2            2  white_starts  ((6, 4), (6, 0))  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRANSLATE MOVE FORMAT TO TUPLES FOR ENGINE INPUT\n",
    "file_to_index = {chr(i): i - ord('a') for i in range(ord('a'), ord('i') + 1)}\n",
    "\n",
    "def translate_move(move):\n",
    "    from_col = file_to_index[move[0]]\n",
    "    from_row = int(move[1]) - 1\n",
    "    to_col = file_to_index[move[3]]\n",
    "    to_row = int(move[4]) - 1\n",
    "\n",
    "    return ((from_row, from_col), (to_row, to_col)) # flipping the file/row order to match with engine input, but uneccesary due to transvariance\n",
    "\n",
    "df['Move_Encoded'] = df['Move'].apply(translate_move)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AUGMENTATION\n",
    "# Maybe later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. BUILD GAMEPLAY WRAPPER\n",
    "from collections import defaultdict\n",
    "\n",
    "class PlayGame():\n",
    "    def __init__(self, data, board):\n",
    "        self.data = data\n",
    "        self.board = board\n",
    "\n",
    "        self.gamestate_counts = defaultdict(int)\n",
    "        self.board_tensors = []\n",
    "        self.policy_vectors = []\n",
    "        self.result_values = []\n",
    "\n",
    "    def run(self):\n",
    "        ids = self.data['Game_ID'].unique()\n",
    "        for id in ids:\n",
    "            self.play_game(id)\n",
    "\n",
    "    def play_game(self, id):\n",
    "        game_data = self.data[self.data['Game_ID'] == id]\n",
    "        #for i in range(8): # Loop through the 8 possible perspectives\n",
    "        # reset board and repetition tracker, build initial tensor\n",
    "        self.gamestate_counts.clear()\n",
    "        self.board.set_starting_position()\n",
    "        self.gamestate_counts[self.board.zobrist_hash] += 1\n",
    "        tensor = self.initial_tensor()\n",
    "\n",
    "        for index, row in game_data.iterrows(): # for turn in game\n",
    "            # get move, store data\n",
    "            self.board_tensors.append(tensor)\n",
    "            self.result_values.append(1 if row['Winner'] == 'White' else 0)\n",
    "\n",
    "            move = row[f'Move_Encoded']\n",
    "            policy_input = np.full(1296, -1) # create policy vector and set move with values set to -1\n",
    "\n",
    "            self.board.generate_moves() # get legal moves for gamestate and set these to 0 in policy vector\n",
    "            for legal_move in self.board.legal_moves:\n",
    "                policy_input[move_to_index[legal_move]] = 0\n",
    "\n",
    "            policy_input[move_to_index[move]] = 1 # set move played to 1 in policy vector\n",
    "            self.policy_vectors.append(policy_input)\n",
    "\n",
    "            # apply move and update repetitions, tensor\n",
    "            self.board.apply_move(move)\n",
    "            self.gamestate_counts[self.board.zobrist_hash] += 1\n",
    "            self.board.repetition_counter = self.gamestate_counts[self.board.zobrist_hash]\n",
    "            tensor = tensor[:-7]\n",
    "            tensor = np.concatenate((self.build_tensor(), tensor, np.full((1,9,9), 1)))\n",
    "\n",
    "    def build_tensor(self):\n",
    "        tensor = np.zeros((6, 9, 9))\n",
    "        # makes the board representation on planes 0-3\n",
    "        for piece in range(4):\n",
    "            for row_index, row in enumerate(self.board.board):\n",
    "                for col_index, col in enumerate(row):\n",
    "                    if col == piece + 1:\n",
    "                        tensor[(piece, row_index, col_index)] = piece\n",
    "        # plane 4 for repetitions\n",
    "        if self.board.repetition_counter > 1:\n",
    "            tensor[4] = np.full((9,9),1)\n",
    "        # plane 5 for turn is 1s for 'White to Move'\n",
    "        if self.board.turn == 1:\n",
    "            tensor[5] = np.full((9,9), 1)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def initial_tensor(self):\n",
    "        tensor = np.zeros((43, 9, 9))\n",
    "        tensor = np.concatenate((self.build_tensor(), tensor))\n",
    "        # plane 48 is all 1s for board vision\n",
    "        tensor[-1] = np.full((9,9), 1)\n",
    "\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor Shape: (22838, 49, 9, 9)\n",
      "Policy Vector Shape: (22838, 1296)\n",
      "Result Values Shape: (22838,)\n"
     ]
    }
   ],
   "source": [
    "zobrist = ZobristHashing()\n",
    "b = Board(zobrist)\n",
    "supervised_game = PlayGame(df, b)\n",
    "\n",
    "supervised_game.run()\n",
    "board_tensors = np.array(supervised_game.board_tensors)\n",
    "policy_vectors = np.array(supervised_game.policy_vectors)\n",
    "result_values = np.array(supervised_game.result_values)\n",
    "\n",
    "# check that number of tensors is equal to number of moves in database\n",
    "assert len(supervised_game.board_tensors) == len(df)\n",
    "print(f'Input Tensor Shape: {board_tensors.shape}')\n",
    "print(f'Policy Vector Shape: {policy_vectors.shape}')\n",
    "print(f'Result Values Shape: {result_values.shape}')\n",
    "\n",
    "# transpose input tensors to put channel last\n",
    "board_tensors = np.transpose(board_tensors, (0, 2, 3, 1))\n",
    "\n",
    "#board_tensors = board_tensors[:10]\n",
    "#policy_vectors = policy_vectors[:10]\n",
    "#result_values = result_values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model on our sample data, which includes ~23,000 board positions from ~500 games. I'm not going to worry to much about tweaking hyperparameters, partially because I can see that is an entire sub-discipline and represents an intractable front, and also because my priority is setting up a usable pipeline and reading endless papers from arxiv is beyond the scope of this project. I will mention that it seems epoch size should be low due to overfitting concerns. Given the paucity of this data, and the large amounts of probable overlap, I won't worry about anything other than getting it to train and seeing my loss functions decrease over epochs. I'm not going to do any validation splits etc, for the same reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m357/357\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 158ms/step - loss: 4.3672\n",
      "Epoch 2/8\n",
      "\u001b[1m357/357\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 160ms/step - loss: 4.3565\n",
      "Epoch 3/8\n",
      "\u001b[1m357/357\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 159ms/step - loss: 4.3083\n",
      "Epoch 4/8\n",
      "\u001b[1m357/357\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 160ms/step - loss: 4.3045\n",
      "Epoch 5/8\n",
      "\u001b[1m357/357\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 160ms/step - loss: 4.2837\n",
      "Epoch 6/8\n",
      "\u001b[1m357/357\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 158ms/step - loss: 4.2596\n",
      "Epoch 7/8\n",
      "\u001b[1m357/357\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 160ms/step - loss: 4.2422\n",
      "Epoch 8/8\n",
      "\u001b[1m357/357\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 160ms/step - loss: 4.2161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.364593982696533,\n",
       "  4.340320110321045,\n",
       "  4.323136806488037,\n",
       "  4.305400371551514,\n",
       "  4.290005683898926,\n",
       "  4.270820140838623,\n",
       "  4.2499494552612305,\n",
       "  4.224168300628662]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "sgd_nesterov = tf.keras.optimizers.SGD(learning_rate=0.2, nesterov=True)\n",
    "\n",
    "model.compile(optimizer = sgd_nesterov, loss={'value_head' : 'mean_squared_error', 'policy_head' : policy_loss})# Fit the model\n",
    "history = model.fit(board_tensors, [policy_vectors, result_values], epochs=8, batch_size=64)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train! and the loss decreases. That's about in line with what I was expecting, and not bad for 8 minutes of training. I expect if I ran any more epochs on this data series I'd just progressively overfit. The real muscle of the Alphazero model comes from the MCTS, the Neural Net is only here to provide (hopefully increasingly reliable) guidance on where to focus, at a much faster speed than random rollouts or handcrafted formulas.\n",
    "\n",
    "Now let's test out ability to generate predictions on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "------------------\n",
      "Policy output: [[-0.29091856  0.72009367  0.32102847 ... -2.1742673   0.668689\n",
      "  -3.019421  ]]\n",
      "Value output: [[1.]]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "example_input = np.expand_dims(board_tensors[3], axis=0)\n",
    "\n",
    "policy_output, value_output = model.predict(example_input)\n",
    "\n",
    "print(\"------------------\")\n",
    "print(\"Policy output:\", policy_output)\n",
    "print(\"Value output:\", value_output)\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate predictions! The negative values in the policy output are mildly concerning - we will be applying softmax to this in any case, but still. On second thought it is unsurprising - with the supervised data that it is being fed, the output should really only be 1 played move and a range of (increasingly unlikely) unplayed moves. This shouldn't be the case during reingforcement learning, where I'll have a populated probability vector. I wonder what I could do to increase performance and ability to generalize with a Supervised approach. Possibly collect moves played from same board position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), (8, 4))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = np.array(tf.nn.softmax(policy_output)).reshape(-1)\n",
    "max_index = np.argmax(probabilities)\n",
    "index_to_move[max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now finally let's try saving our trained mini supervised model, and make sure we don't run into any issues serializing or deserializing. Then we can try regenerating the predictions we just made and check that we're able to reliably load our model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('../saved_models/supervised_model_tablut_muninn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
      "------------------\n",
      "Policy output: [[-0.29091856  0.72009367  0.32102847 ... -2.1742673   0.668689\n",
      "  -3.019421  ]]\n",
      "Value output: [[1.]]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model(\"../saved_models/supervised_model_tablut_muninn.keras\", custom_objects={'loss': policy_loss})\n",
    "policy_output_1, value_output_1 = loaded_model.predict(example_input)\n",
    "\n",
    "print(\"------------------\")\n",
    "print(\"Policy output:\", policy_output)\n",
    "print(\"Value output:\", value_output)\n",
    "print(\"------------------\")\n",
    "\n",
    "# check that the predictions are the same (all the weights and layers serialised/reserialised properly)\n",
    "assert (policy_output_1 == policy_output).all() and (value_output_1 == value_output).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Next step is beginning to implement the MCTS wrappers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas:\n",
    "Encoding repetitions: could have flag that shows that a loss by repetition is possible, and then mark the square that would lead to repetition. This would only add 2 extra squares, but overengineering the feature? Also not sure how this would apply to black. Takes away from the simplicity and 'zero' nature. Might as well start adding flags when a win is immediately available etc. (though this isnt a bad idea for endgame situations in competitive play!)\n",
    "\n",
    "ON TUNING FROM Lc0:\n",
    "I don't think we have much experience outside of SGD for 'very long term training' - some people have had reasonable short term results in SL using Adam/AdamW.\n",
    "our current long term RL training strategy is basic SGD momentum with lookahead - lookahead does not clearly actually add value (after adjusting the LR upwards by 2 to offset its LR reducing effect), but there were some somewhat positive signs (maybe faster even if not better) so we haven't bothered turning it off. \n",
    "Regularization our current strategy is manually decayed L2 regularization \n",
    "when we do LR drops - we also reduce regularization weight, by a smaller factor.\n",
    "selfplay train ratio is 64k new games into training window per 2k steps of batch size 1024.  Each game has ... about 80 positions on average (been a while since I checked that average, could be wrong...)\n",
    "so positions are sampled about 50% on average.  Although since we used biased sampling, some positions are sampled way more than others.\n",
    "since we use deblundering, game outcome scores are less correlated than they used to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography:\n",
    "\n",
    "Alpha Zero Paper\\\n",
    "https://arxiv.org/pdf/1712.01815\n",
    "\n",
    "Alpha Go Paper\\\n",
    "https://discovery.ucl.ac.uk/id/eprint/10045895/1/agz_unformatted_nature.pdf\n",
    "\n",
    "Neural Networks for Chess\\\n",
    "https://arxiv.org/abs/2209.01506\n",
    "\n",
    "Leela Chess Zero\\\n",
    "https://lczero.org/\n",
    "\n",
    "-----------------\n",
    "\n",
    "Squeeze and Excitation Networks\\\n",
    "https://arxiv.org/pdf/1709.01507\n",
    "\n",
    "Squeeze and Excitation Python/Tensorflow Implementation\\\n",
    "https://github.com/taki0112/SENet-Tensorflow\n",
    "\n",
    "Competitive SE Blocks\\\n",
    "https://arxiv.org/pdf/1807.08920\n",
    "\n",
    "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\\\n",
    "https://arxiv.org/pdf/1502.03167\n",
    "\n",
    "Group Normalization\\\n",
    "https://arxiv.org/pdf/1803.08494\n",
    "\n",
    "Deep Residual Learning for Image Recognition\\\n",
    "https://arxiv.org/pdf/1512.03385\n",
    "\n",
    "Convolution Arithmetic for Deep Learning\\\n",
    "https://arxiv.org/pdf/1603.07285v1\n",
    "\n",
    "Visualising and Understanding CNNs\\\n",
    "https://arxiv.org/pdf/1311.2901\n",
    "\n",
    "Fast Algorithms for Convolutional Neural Networks\\\n",
    "https://arxiv.org/pdf/1509.09308\n",
    "\n",
    "Attention Is All You Need\\\n",
    "https://arxiv.org/pdf/1706.03762\n",
    "\n",
    "What do Neural Loss Surfaces Look Like\\\n",
    "https://www.youtube.com/watch?v=78vq6kgsTa8\\\n",
    "\n",
    "Sophia Optimizer\\\n",
    "https://arxiv.org/pdf/2305.14342\n",
    "\n",
    "Adam Optimizer\\\n",
    "https://arxiv.org/pdf/1412.6980\n",
    "\n",
    "SGD Generalizing Better than Adam\\\n",
    "https://arxiv.org/pdf/2010.05627\n",
    "\n",
    "On the importance of initialization and momentum in deep learning (Nesterovs Accelerated Gradient)\\\n",
    "https://proceedings.mlr.press/v28/sutskever13.pdf\n",
    "\n",
    "Optimization Bible - Algorithms for Optimization\\\n",
    "https://algorithmsbook.com/optimization/files/optimization.pdf\n",
    "\n",
    "The Marginal Value of Adaptive Gradient Methods in Machine Learning\\\n",
    "https://arxiv.org/pdf/1705.08292\n",
    "\n",
    "Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates\\\n",
    "https://arxiv.org/pdf/1708.07120\n",
    "\n",
    "Cross-entropy Loss\\\n",
    "https://machinelearningmastery.com/cross-entropy-for-machine-learning/\n",
    "\n",
    "\n",
    "\n",
    "--------------\n",
    "Reinforcement Learning 10: Classic Games Case Study\\\n",
    "https://www.youtube.com/watch?v=ld28AU7DDB4&ab_channel=GoogleDeepMind\n",
    "\n",
    "Monte Carlo Tree Search\\\n",
    "https://www.youtube.com/watch?v=UXW2yZndl7U&t=2s&ab_channel=JohnLevine\n",
    "\n",
    "----------------\n",
    "\n",
    "Why a Constant Plane of 1s in Input?\\\n",
    "https://ai.stackexchange.com/questions/11014/why-is-a-constant-plane-of-ones-added-into-the-input-features-of-alphago\n",
    "\n",
    "-------------\n",
    "A New Hashing Method with Application for Game Playing - Zobrist\\\n",
    "https://research.cs.wisc.edu/techreports/1970/TR88.pdf\n",
    "\n",
    "Why are Initial Zobrist Elements Random?\\\n",
    "https://cs.stackexchange.com/questions/22033/why-is-the-initial-state-of-zobrist-hashing-random\n",
    "\n",
    "-------------\n",
    "Discussion around Leela Policy Head\\\n",
    "https://github.com/glinscott/leela-chess/issues/47\n",
    "\n",
    "Lc0 Discord\\\n",
    "https://discord.com/channels/425419482568196106/427066771627966466/1088003369781698590\n",
    "\n",
    "---------------\n",
    "Temperature and Softmax\\\n",
    "https://stats.stackexchange.com/questions/527080/what-is-the-role-of-temperature-in-softmax\n",
    "\n",
    "Excellent Description of Cross-Entropy Calculation and Softmax\\\n",
    "https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop/39499486#39499486\n",
    "\n",
    "More on Mathematics of Information Theory, Cross-entropy\\\n",
    "https://datascience.stackexchange.com/questions/9302/the-cross-entropy-error-function-in-neural-networks\n",
    "\n",
    "Binary Cross Entropy-loss Visualisation\\\n",
    "https://www.youtube.com/watch?v=DPSXVJF5jIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
